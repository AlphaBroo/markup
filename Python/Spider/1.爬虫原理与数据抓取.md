# 爬虫分类

## 通用爬虫

```
通用网络爬虫 是 捜索引擎抓取系统（Baidu、Google、Yahoo等）的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。
```

通用搜索引擎网络爬虫工作流程

```
1.抓取网页
2.数据存储
3.预处理
4.提供检索服务，网站排名
```

局限

```
1.通用搜索引擎所返回的结果都是网页，而大多情况下，网页里90%的内容对用户来说都是无用的。
2.不同领域、不同背景的用户往往具有不同的检索目的和需求，搜索引擎无法提供针对具体某个用户的搜索结果。
3.万维网数据形式的丰富和网络技术的不断发展，图片、数据库、音频、视频多媒体等不同数据大量出现，通用搜索引擎对这些文件无能为力，不能很好地发现和获取。
4.通用搜索引擎大多提供基于关键字的检索，难以支持根据语义信息提出的查询，无法准确理解用户的具体需求。
```

## 聚焦爬虫

```
聚焦爬虫，是"面向特定主题需求"的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于： 聚焦爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息。
```

# HTTP/HTTPS

```
HTTP协议：是一种发布和接收 HTML页面的方法。

HTTPS简单讲是HTTP的安全版，在HTTP下加入SSL层。

SSL（Secure Sockets Layer 安全套接层）主要用于Web的安全传输协议，在传输层对网络连接进行加密，保障在Internet上数据传输的安全。

HTTP的端口号为80，
HTTPS的端口号为443
```

## URL

```
URL（Uniform / Universal Resource Locator的缩写）：统一资源定位符，是用于完整地描述Internet上网页和其他资源的地址的一种标识方法。

基本格式：scheme://host[:port]/path/…/[?query-string][#anchor]

scheme：协议(例如：http, https, ftp)
host：服务器的IP地址或者域名
port：服务器的端口（如果是走协议默认端口，缺省端口80）
path：访问资源的路径
query-string：参数，发送给http服务器的数据
anchor：锚（跳转到网页的指定锚点位置）
```

## 客户端HTTP请求

HTTP是用来提交和获取资源。客户端发送一个HTTP请求到服务器的请求消息，包括以下格式：

`请求行`、`请求头部`、`空行`、`请求数据`

###常用请求方法

`GET https://www.baidu.com/ HTTP/1.1`

| 描述   |                                                              |
| ------ | ------------------------------------------------------------ |
| GET    | 请求指定的页面信息，并返回实体主体。请求参数都显示在URL中    |
| POST   | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件），数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 |
| PUT    | 从客户端向服务器传送的数据取代指定的文档的内容。             |
| DELETE | 请求服务器删除指定的页面。                                   |

### 常用请求报头

```
Host (主机和端口号)
Connection (连接类型)
Upgrade-Insecure-Requests (升级为HTTPS请求)
User-Agent (浏览器名称)
Accept (传输文件类型)
Referer (页面跳转来源)
Accept-Encoding（文件编解码格式）
Accept-Language（语言种类）
Accept-Charset（字符编码）
Cookie （Cookie）
Content-Type (POST数据类型)
```

## 服务端HTTP响应

HTTP响应也由四个部分组成，分别是： `状态行`、`消息报头`、`空行`、`响应正文`

### 常用响应报头

```
Cache-Control：must-revalidate, no-cache, private
Connection：keep-alive
Content-Encoding:gzip
Content-Type：text/html;charset=UTF-8
Date：Sun, 21 Sep 2016 06:18:21 GMT
Expires:Sun, 1 Jan 2000 01:00:00 GMT
Pragma:no-cache
Server：Tengine/1.4.6
Transfer-Encoding：chunked
Vary: Accept-Encoding
```

### 常用响应状态码

```
100~199：表示服务器成功接收部分请求，要求客户端继续提交其余请求才能完成整个处理过程。

200~299：表示服务器成功接收请求并已完成整个处理过程。常用200（OK 请求成功）。

300~399：为完成请求，客户需进一步细化请求。例如：请求的资源已经移动一个新地址、常用302（所请求的页面已经临时转移至新的url）、307和304（使用缓存资源）。

400~499：客户端的请求有错误，常用404（服务器无法找到被请求的页面）、403（服务器拒绝访问，权限不够）。

500~599：服务器端出现错误，常用500（请求未完成。服务器遇到不可预知的情况）。
```

# 网站信息

```
1.检查robots.txt
robots.txt	# 爬取该网站存在的限制
2.检查网站地图
Sitemap		# 网站地图，存在缺失、过期或不完整
3.估算网站大小
在google中使用site关键词
site:网站地址
4.识别网站所使用的技术
pip install builtwith
import builtwith
builtwith.parse('网站地址')
5.寻找网站的所有者
pip install python-whois
import whois
print whois.whois('域名')
```




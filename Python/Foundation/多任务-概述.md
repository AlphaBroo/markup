[TOC]

# 多任务-概述

考虑有这样一个程序，需要监听一个套接字的连接，并处理收到的连接。有以下三种解决方案

- 每次有新连接建立时就创建(fork)一个新进程，需要用到multiprocessing
- 每次有心连接建立时创建一个新线程，需要用threading
- 将这个新连接加入事件循环(event loop)中，并在事件发生时对其作出响应

## 进程/线程

### 概述

```
进程是程序的一次执行，每个进程都有自己的地址空间、内存、数据栈以及记录运行轨迹的辅助数据，操作系统管理运行的所有进程，并为这些进程公平分配时间。进程可以通过fork和spawn操作完成其他任务。因为各个进程有自己的内存空间、数据栈等，所有只能使用进程间通信(IPC)，而不能直接共享信息

线程有开始、顺序执行和结束3部分，有一个自己的指令指针，记录运行到什么地方。线程的运行可能被抢占(中断)或暂时被挂起，从而让其他线程运行(让步)。一个进程中的各个线程之间共享一片数据空间，所以线程比进程更方便进行数据共享和通信。

线程是最小的执行单元，线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

对于操作系统来说，一个任务就是一个进程（Process)
在一个进程内部，同时运行多个“子任务”,进程内的这些“子任务”称为线程（Thread）

一个程序至少有一个进程,一个进程至少有一个线程.如何调度进程和线程，完全由操作系统决定，程序自己不能决定什么时候执行，执行多长时间。

多任务的实现有3种方式：
多进程模式；
多线程模式；
多进程+多线程模式

要实现多任务，通常我们会设计Master-Worker模式，Master负责分配任务，Worker负责执行任务，因此，多任务环境下，通常是一个Master，多个Worker。
如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。
如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。
```

### GIL

```
Python语言和GIL没有半毛钱关系。仅仅是由于历史原因在Cpython虚拟机(解释器)，难以移除GIL。

python代码的执行由python虚拟机(解释器主循环)控制。python虚拟机的访问由GIL控制。

GIL：全局解释器锁。在Python的主流实现CPython中，GIL是一个全局线程锁，每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行代码。

线程释放GIL锁的情况：
在python2中，GIL释放逻辑是当前线程遇见IO操作或者ticks计数达到100(ticks可视为python本身的一个计数器，专门用于GIL，每次释放后归零，这个计数可以通过sys.setcheckinterval来调整)时进行释放。
在python3中，GIL不使用ticks计数，改为使用计时器计数(执行时间达到阈值后，当前线程释放GIL)。

在多线程环境中，python虚拟机按以下方式执行：
1.设置GIL
2.切换到一个线程执行
3.运行指定数量的字节码指令或线程主动让出控制(可电泳time.sleep(0))
4.把线程设置为睡眠状态
5.解锁GIL
6.再次重复以上所有步骤

Python使用多进程是可以利用多核的CPU资源的。

多线程爬取比单线程性能有提升，因为遇到IO阻塞会自动释放GIL锁

在处理像科学计算 这类需要持续使用cpu的任务的时候 单线程会比多线程快
在处理像IO操作等可能引起阻塞的这类任务的时候 多线程会比单线程快
```

### 优缺点

```
多进程模式优点
稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。

多进程模式缺点
创建进程的代价大，在Unix/Linux系统下，用fork调用还行，在Windows下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。

多线程模式通常比多进程快一点
多线程模式致命的缺点
任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。
由于数据访问顺序不一样，有可能导致手结果不一致的问题，形成竞态条件，故大多数线程库带有一系列同步原语，用于控制线程的执行和数据访问。

操作系统在切换进程或者线程时，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。

在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式
```

## 目的:并行/并发

Python中，多线程和多进程的目的是为了事项多任务，最大程度地利用计算机资源，更好地实现并发和并行。

```
单核CPU执行多线程：操作系统轮流让各个任务交替执行，真正的并行执行多任务只能在多核CPU上实现
多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，真正地同时执行多线程需要多核CPU才可能实现

并发：指的是任务数多余cpu核数，通过操作系统的各种任务调度算法，实现用多个任务“一起”执行（实际上总有一些任务不在执行，因为切换任务的速度相当快，看上去一起执行而已）

并行：指的是任务数小于等于cpu核数，即任务真的是一起执行的

并发：交替处理多个任务的能力
并行：同时处理多个任务的能力

多线程并不能真正的让多核cpu实现并行

原因 : cpython解释器中存在一个GIL(全局解释器锁),他的作用就是保证同一时刻只有一个线程可以执行代码,因此造成了我们使用多线程的时候无法实现并行

解决方案法 :
1:更换解释器 比如使用jpython(java实现的python解释器)
2:使用多进程完成多任务的处理
```

## 应用场景

IO密集型/CPU密集型

```
CPU密集型
音视频数据编解码、复杂计算属于CPU密集型应用场景。在这种情况下，由于计算工作多，消耗CPU资源，因此不管是ticks计数还是定时器很快就会达到阈值，然后触发GIL的释放与再竞争。因为python多线程无法利用CPU多核，所以多线程不合适，多进程时合适的。要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。

计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。

IO密集型
网络操作、磁盘IO的任务都是IO密集型任务。在单线程下，当有IO操作时会进行IO等待，造成不必要的时间浪费，而开启多线程能在一个线程等待IO时切换到另一个线程，可以不浪费CPU资源，从而提升程序的执行效率，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，故python的多线程是合适的，但也有一个限度。

IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。
```

## 程序状态

### 同步/异步

```
同步和异步关注的是消息通信机制 
同步：在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。由*调用者*主动等待这个*调用*的结果。
异步：当一个异步过程调用发出后，调用者不会立刻得到结果。就直接返回了去执行其他的操作。在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。

同步：执行一个操作之后，等待结果，然后才继续执行后续的操作。

异步：执行一个操作后，可以去执行其他的操作，然后等待通知再回来执行刚才没执行完的操作。
```

### 阻塞/非阻塞

```
阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.
阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

阻塞：进程给CPU传达一个任务之后，一直等待CPU处理完成，然后才执行后面的操作。

非阻塞：进程给CPU传达任我后，继续处理后续的操作，隔断时间再来询问之前的操作是否完成。这样的过程其实也叫轮询
```

阻塞、非阻塞、多路IO复用，都是同步IO，异步必定是非阻塞的，所以不存在异步阻塞和异步非阻塞的说法。真正的异步IO需要CPU的深度参与。换句话说，只有用户线程在操作IO的时候根本不去考虑IO的执行全部都交给CPU去完成，而自己只等待一个完成信号的时候，才是真正的异步IO。所以，拉一个子线程去轮询、去死循环，或者使用select、poll、epool，都不是异步。

## 网络IO模型

分类

````
同步模型
阻塞IO（bloking IO）
非阻塞IO（non-blocking IO）
多路复用IO（multiplexing IO）
信号驱动式IO（signal-driven IO）

异步模型
异步IO（asynchronous IO）
````

网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。对于一次IO访问，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间，所以一般会经历两个阶段：

1. 等待所有数据都准备好或者一直在等待数据，有数据的时候将数据拷贝到系统内核；
2. 将内核缓存中数据拷贝到用户进程中；

对于socket流而言：

1. 等待网络上的数据分组到达，然后被复制到内核的某个缓冲区；
2. 把数据从内核缓冲区复制到应用进程缓冲区中；

## 异步IO

```
考虑到CPU和IO之间巨大的速度差异，一个任务在执行的过程中大部分时间都在等待IO操作，单进程单线程模型会导致别的任务无法并行执行，因此，我们才需要多进程模型或者多线程模型来支持多任务并发执行。

现代操作系统对IO操作已经做了巨大的改进，最大的特点就是支持异步IO。如果充分利用操作系统提供的异步IO支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为事件驱动模型，Nginx就是支持异步IO的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。由于系统总的进程数量十分有限，因此操作系统调度非常高效。用异步IO编程模型来实现多任务是一个主要的趋势。

对应到Python语言，单线程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。
```

# Epoll

（1）多路 I/O 复用模型

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

**这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。**采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

（1） 网络IO都是通过Socket实现，Server在某一个端口持续监听，客户端通过Socket（IP+Port）与服务器建立连接（ServerSocket.accept），成功建立连接之后，就可以使用Socket中封装的InputStream和OutputStream进行IO交互了。针对每个客户端，Server都会创建一个新线程专门用于处理 
（2） 默认情况下，网络IO是阻塞模式，即服务器线程在数据到来之前处于【阻塞】状态，等到数据到达，会自动唤醒服务器线程，着手进行处理。阻塞模式下，一个线程只能处理一个流的IO事件 
（3） 为了提升服务器线程处理效率，有以下三种思路

> （1）非阻塞【忙轮询】：采用死循环方式轮询每一个流，如果有IO事件就处理，这样可以使得一个线程可以处理多个流，但是效率不高，容易导致CPU空转
>
> （2）Select代理（无差别轮询）：可以观察多个流的IO事件，如果所有流都没有IO事件，则将线程进入阻塞状态，如果有一个或多个发生了IO事件，则唤醒线程去处理。但是还是得遍历所有的流，才能找出哪些流需要处理。如果流个数为N，则时间复杂度为O（N）
>
> （3）Epoll代理：Select代理有一个缺点，线程在被唤醒后轮询所有的Stream，还是存在无效操作。 Epoll会哪个流发生了怎样的I/O事件通知处理线程，因此对这些流的操作都是有意义的，复杂度降低到了O(1)




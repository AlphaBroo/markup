# 分布式

分布式计算的基本理念是将工作划分位一个一个的小任务，通常每个任务都有名称。分布式网络中的电脑可以完美无缺地完成这些合理大小的任务并返回结果。在分布式计算中，网络中的机器必须要保持可用(延迟误差、意外宕机、电脑联网等)。因此，需要一个持续监控架构。

使用这种技术所带来的根本问题，主要在于对(传输与接收没有出错)流量(数据、工作、命令等)的合理管理。另外，还有一个源自分布式计算基本特征的问题：分布式网络中共存的机器支持不同的操作系统，而这些系统通常相互不兼容。事实上，由于需要在分布式环境中使用多种多样的资源，逐渐出现了不同的计算模型。它们的目标基本上都是为如何描述分布式应用的进程之间的协作提供框架。可以这样说，不同的模型的区别基本在于其对分布式所提供机会的利用能力。使用最广泛的模型是客户端-服务端(client-server)模型。它可以让位于不同电脑中的进程通过交换信息实现实时协作，因此性能比之前的模型有很大的提升，后者要求转移所有的文件，而且要离线对数据进行计算。客户端-服务器模型通常通过远程进程调用(扩大本机调用的范围)，或分布式对象范式(面向对象中间件)实现。

常用的与面向对象模式和远程调用模式实现分布式架构的库，如Celery、SCOOP、Pyro4、RPyc，以及使用其他不同方法实现的库，如PyCSP和Disco，后两者是python中对应于MapReduce的算法

## Celery

celery是一个用于管理分布式任务的python框架，采用的是面向对象中间件的方法实现。其主要特性包括处理大量小型任务，并将其分发给大量计算节点。最后，每个任务的结果重新组合，构成最终的答案。

Celery是由Python开发、简单、灵活、可靠的分布式任务队列，其本质是生产者消费者模型，生产者发送任务到消息队列，消费者负责处理任务。Celery侧重于实时操作，但对调度支持也很好，其每天可以处理数以百万计的任务。

Celery由以下三部分构成：消息中间件(Broker)、任务执行单元Worker、结果存储(Backend)

![消息中介架构](images/消息中介架构.png)

celery通过消息进行通信，通常使用一个叫Broker(中间人)来协client(任务的发出者)和worker(任务的处理者). clients发出消息到队列中，broker将队列中的信息派发给worker来处理。

工作原理

```
- 任务模块Task包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往消息队列，而定时任务由Celery Beat进程周期性地将任务发往消息队列；

- 任务执行单元Worker实时监视消息队列获取队列中的任务执行；

- Woker执行完任务后将结果保存在Backend中;
```

应用场景

```
- web应用
当用户在网站进行某个操作需要很长时间完成时，我们可以将这种操作交给Celery执行，直接返回给用户，等到Celery执行完成以后通知用户，大大提好网站的并发以及用户的体验感。

- 任务场景
比如在运维场景下需要批量在几百台机器执行某些命令或者任务，此时Celery可以轻松搞定。

- 定时任务
向定时导数据报表、定时发送通知类似场景，虽然Linux的计划任务可以帮我实现，但是非常不利于管理，而Celery可以提供管理接口和丰富的API。
```

### 安装

使用python的包管理器pip来安装:

```
pip install -U Celery
```

从官方直接下载安装包:<https://pypi.python.org/pypi/celery/>

```
tar xvfz celery-0.0.0.tar.gz
cd celery-0.0.0
python setup.py build
python setup.py install
```

### broker

消息中介是一个不依赖于celery的软件组件，是一个中间件，用于向分布式任务工作进程发送和接收消息。消息中介也被称为消息中间件。它负责通信网络中的消息交换。这类中间件的编址方案(addressing scheme)不再是点对点式的，而是面向消息式的，其中最知名的就是发布/订阅范式。Celery支持多种类型的消息中介，如RabbitMQ、Redis、Amazon SQS、MongoDB、Memcached 等，其中最为完整的是RabbitMQ和Redis。

- RabbitMQ

它是一个面向消息的中间件(中介消息传递，broker messaging)，它实现了高级消息队列协议(AMQP)。RabbitMQ采用Erlang语言编写，其基础是用于管理集群和故障切换的开放电信平台(OTP)框架。

使用RabbitMQ的细节参照以下链接：<http://docs.celeryproject.org/en/latest/getting-started/brokers/rabbitmq.html#broker-rabbitmq>

```
RabbitMQ是一个功能完备，稳定的并且易于安装的broker. 它是生产环境中最优的选择。

如果我们使用的是Ubuntu或者Debian发行版的Linux，可以直接通过下面的命令安装RabbitMQ: sudo apt-get install rabbitmq-server 安装完毕之后，RabbitMQ-server服务器就已经在后台运行。如果您用的并不是Ubuntu或Debian, 可以在以下网址： http://www.rabbitmq.com/download.html 去查找自己所需要的版本软件。
```

- Redis

关于是有那个Redis作为Broker，可访下面网址：<http://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html#broker-redis>

```
Redis也是一款功能完备的broker可选项，但是其更可能因意外中断或者电源故障导致数据丢失的情况。
```

### worker

Worker是任务执行单元，负责从消息队列中取出任务执行，它可以启动一个或者多个，也可以启动在不同的机器节点，这就是其实现分布式的核心

```python
# 我们首先创建tasks.py模块
from celery import Celery

# 我们这里案例使用redis作为broker
# Celery第一个参数是给其设定一个名字， 第二参数我们设定一个中间人broker
app = Celery('demo', broker='redis://127.0.0.1/1')
# app = Celery('demo', broker='amqp://guest@localhost//')

# 创建任务函数, 通过加上装饰器app.task, 将其注册到broker的队列中
@app.task
def my_task():
    print("任务函数正在执行....")
```

现在我们在创建一个worker， 等待处理队列中的任务.打开终端，cd到tasks.py同级目录中，执行命令:

```
celery -A tasks worker --loglevel=info

celery -A tasks worker -l info
```

### backend

Backend结果存储官方也提供了诸多的存储方式支持：RabbitMQ、 Redis、Memcached,SQLAlchemy, Django ORM、Apache Cassandra、Elasticsearch。

使用Redis作为存储结果的方案，任务结果存储配置我们通过Celery的backend参数来设定。我们将tasks模块修改如下:

```python
# 修改tasks.py
from celery import Celery

# 我们这里案例使用redis作为broker
# 我们给Celery增加了backend参数，指定redis作为结果存储,并将任务函数修改为两个参数，并且有返回值。
app = Celery('demo',
backend='redis://127.0.0.1:6379/2',
broker='redis://127.0.0.1:6379/1')

# 创建任务函数
@app.task
def my_task(a, b):
    print("任务函数正在执行....")
    return a + b
```

### 任务执行

任务加入到broker队列中，以便刚才我们创建的celery workder服务器能够从队列中取出任务并执行。如何将任务函数加入到队列中，可使用如下方法

```python
# 该任务发送一个任务消息
apply_async(args[, kwargs[, ...]])
# 发送任务消息的便捷方法，不支持添加执行选项
delay(*args, **kwargs)

# 使用样例
task.delay(arg1, arg2, kwarg1='x', kwarg2='y')
task.apply_async(args=[arg1, arg2], kwargs={'kwarg1':'x', 'kwarg2':'y'})
```

默认多进程执行，也可以多协程处理(greenlet/gevent)

进入python终端, 执行如下代码:

```python
from tasks import my_task
# 执行,返回执行的对象
task_obj = my_task.delay()
# 获取任务编号
print(task_obj.id)
# 获取异步任务结果，默认阻塞
task_obj.get()
```

- django中使用

```python
# 创建和开启任务
from celery import Celery
import os

os.environ["DJANGO_SETTINGS_MODULE"] = "dj_py2_demo.settings"

# django不不需开启，celery端需要开启
# import django
# django.setup()

app = Celery(
    'sum_two',
    broker='redis://127.0.0.1:6379/1',
    backend='redis://127.0.0.1:6379/2',
)

@app.task
def sum_two(a, b):
    c = a + b
    return c

# 发布和获取结果
from celery_tasks.sum_two import sum_two

result = sum_two.delay(5,7)
result.get()
```

### 任务监控

flower是一个用于监控任务(运行进度、任务详情、图标、数据)的web工具。

```python
# 安装
pip install -U flower

# 运行flower命令启动web-server
celery -A proj flower

# 设置端口
# 缺省的端口是http://localhost:5555, 可以使用–port参数改变
celery -A proj flower --port=5555

# 设置broker的URL
celery flower --broker=amqp://guest:guest@localhost:5672//
celery flower --broker=redis://guest:guest@localhost:6379/0    

# 浏览器访问
open http://localhost:5555
        
# api使用
# 获取woker信息
curl http://127.0.0.1:5555/api/workers
```

## SCOOP

SCOOP全称Scalable Concurrent Operations in Python，意为"python中的可伸缩式并发运算"，是一个将并发任务(被称为Futures)分发在异构计算节点(heterogeneous computational nodes)上运行的python模块。其架构基于MQ包，后者提供了在分布式系统之间管理Futures的方法。SCOOP应用在需要使用全部可用计算资源执行诸多分布式任务的科学计算。

SCOOP采用了如下所示的这种中介模式来分发Futures。

![SCOOP架构](images/SCOOP架构.png)

通信系统的核心元素时负责于所有独立工作者进程交互、调度消息的中介。Futures并非创建于中心节点(中介)，而是通过一套统一的序列化程序在各个工作者进程中创建。这使得其拓扑架构更可靠，性能更高。实际上，中介的主要工作负载由网络和工作者进程间I/O构成，所需的CPU处理事件相对较少。

### 安装

SCOOP模块可在`https://github.com/soravux/scoop/`处获取，所需依赖如下

```
python>=2.6或>=3.2
Distribute>=0.6.2或setuptools>=0.7
Greenlet>=0.3.4
pyzmq>=13.1.0及libzmq>=3.2.0
SSH(用于远程执行)
```

和Disco一样，远程使用SCOOP需要SSH软件，而且哥哥节点之间必须开启为无须密码验证。

```python
# pip安装
pip install SCOOP
# 发布版的目录下安装
python setup.py install
```

### 科学计算

SCOOP库具有许多功能，主要用于科学计算。尽管求解科学计算问题的方法十分耗费计算资源，但幸好出现了蒙特卡罗算法。

如何使用SCOOP的特性并行化蒙特卡罗方法求解以下问题：计算数字$\pi$

```python
import math
from random import random
from scoop import futures
from time import time

def evaluate_number_of_points_in_unit_circle(attempts):
    points_fallen_in_unit_disk = 0
    for i in range(0, attempts):
        x = random()
        y = random()
        radius = math.sqrt(x*x + y*y)
        # 如果点落在单位圆内，则测试通过
        if radius < 1:
            # 测试通过后，增加圆内点的数目
            points_fallen_in_unit_disk  = points_fallen_in_unit_disk + 1
    return points_fallen_in_unit_disk


def pi_calculus_with_Montecarlo_Method(workers, attempts):
    print("number of workers %i - number of attempts %i" % (workers, attempts))
    bt = time()
    # 这时我们调用scoop.futures.map函数，然后求单位圆内点的数目
    # 函数以异步方式执行并且可以并发多次调用该函数
    evaluate_task = futures.map(evaluate_points_in_circle, [attempts] * workers)
    taskResult = sum(evaluate_task)
    print("%i points fallen in a unit disk after " % (taskResult/attempts))
    piValue = (4. * taskResult/float(workers * attempts))

    computationalTime = time() - bt
    print("value of pi = " + str(piValue))
    print("error percentage = " + str((((abs(piValue - math.pi)) * 100)/ math.pi)))
    print("total time: " + str(computationalTime))

if __name__ == "__main__":
    for i in range(1, 4):
        # 将工作者数量固定为2，也可以设置更高
        pi_calculus_with_Montecarlo_Method(i*1000, i*1000)
        print(" ")
```

运行

```
python -m scoop name_file.py
```

### 映射函数

在处理列表或其他数据序列时，有一个常见任务，即对列表中的每个元素应用相同的操作，然后收集结果。

```python
# 方法一
items = [1,2,3,4,5,6,7,8,9]
updated_items = []
for x in items:
    updated_items.append(x*2)
print(updated_items)   
# 方法二
items = [1,2,3,4,5,6,7,8,9]
def multipyFor2(x): return x*2
print(list(map(multipyFor2, items)))
# 方法三
items = [1,2,3,4,5,6,7,8,9]
print(list(map(lambda x:x*2, items)))
```

SCOOP模块定义了多个映射函数，支持可传播至其工作者的异步计算，如下

| 方法                                                         | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `futures.map(func, iterables, kargs)`                        | 返回一个以输入中相同顺序迭代结果的生成器。可作为标准库中的map()函数的并行版 |
| `futures.map_as_completed(func, iterables, kargs)`           | 只要结果一可用即生成结果                                     |
| `futures.scoop.futures.mapReduce(mapFunc, reductionOp, iterables, kargs)` | 支持在应用map()函数后将减项函数(reduction function)并行化，返回单个元素 |

对比MapReduce函数的SCOOP实现和串行实现

```python
import operator
import time
from scoop import futures


def simulateWorkload(inputData):
    # 模拟真实的计算工作负载
    time.sleep(0.01)
    return sum(inputdata)

def compareMapReduce():
    # SCOOP版的MapReduce
    mapScoopTime = time.time()
    # 参数1:调用该函数可执行Futures，可调用对象必须返回一个值
    # 参数2:调用该函数可归约(reduce)Futures运行结果，必须接受两个参数，并返回一个单一值
    # 参数3:将作为单独的Future传入可调用对象的可迭代对象
    res = futures.mapReduce(
        simulateWorkload,
        operator.add,
        list([a] * a for a in range(1000)),
    )
    mapScoopTime = time.time() - mapScoopTime
    print("futures.map in SCOOP executed in {0:3f}s with result: {1}".format(mapScoopTime, res))
	# 串行版的MapReduce
    mapPythonTime = time.time()
    # map()函数参数1:函数，参数2:可迭代对象
    # 为了结果规约，使用sum函数
    res = sum(
        map(
            simulateWorkload,
            list([a] * a for a in range(1000))
        )
    )
    mapPythonTime = time.time() - mapPythonTime
    print("map python executed in: {0:.3f}s with result: {1}".format(mapPythonTime, res))

    if __name__ == "__main__":
        compareMapReduce()
```

运行

```
python -m scoop map_reduce.py
```

## Pyro4

python远程对象(Python Remote Objects，简称Pyro4)是一个类似java中远程方法调用(Remote Method Invocation，简称RMI)的库，支持调用远程对象(属于不同的进程，可能位于另一台机器上)的方法，就好像它就是本地对象(同属于运行调用的那个进程)。远程过程调用(remote procedure call，简称RPC)的概念被按照面向对象范式重新组织(在面向对象的范式中，方法取代了过程)。在面向对象系统中使用远程方法调用机制，可以为项目带来极大的一致性、对称性优势，因为它可以让我们使用同一个概念工具来模拟分布式进程之间的交互，该工具也被用于表示一个应用或方法调用中不同对象的交互

Pyro4支持以客户端-服务器的形式管理和分发对象。这意味着一个Pyro4系统的主要部分可以从一个调用远程对象的客户端切换到一个调用来提供函数的对象。注意：在远程调用期间，一直存在两个明显的部分，即客户端发起调用，服务端接收并执行客户端调用。最后，这个机制的管理均由Pyro4以分布式的方式进行。

### 安装

```python
# pip安装
pip install pyro
# 包安装
python setup.py install
```

### 远程调用

使用pyro4中间件构建并使用一个简单的客户端-服务器通信

- server

```python
import Pyro4

# 远程访问对象Server类
class Server(object):
    # Server类的实例方法
    def welcomeMessage(self, name):
        return ("Hi welcome " + str(name))

    def startServer():
        # 构建类的实例
        server = Server()
        # 创建一个Pyro守护程序
        # 使用守护程序对象将传入的调用请求分配给相应的对象。服务器必须创建一个负责管理实例的守护程序
        # 每个服务器都有一个这样的守护程序，它掌握了该服务器提供的所有Pyro对象
        daemon = Pyro4.Daemon()
        # 执行脚本前，必须运行一个Pyro名称服务器，因此需定位该名称服务器
        ns = Pyro4.locateNS()
        # 需要将该服务器注册为Pyro对象object,只有在Pyro守护程序内部才知道该对象
        # 返回注册对象的URI
        uri = daemon.register(server)
        # 在名称服务器中使用一个名称注册该对象服务器
        ns.register("server", uri)
        print("Ready. Object uri = ", uri)
        # 函数运行结束，将调用守护程序的eventloop方法。将启动服务器的事件循环，并等待其他调用传入
        daemon.requestLoop()

if __name__ == "__main__":
    startServer()
```

- client

```python
import Pyro4

uri = input("What is the Pyro uri of the greeting object?")
name = input("What is your name? ").strip()
# 客户端向服务器发送执行命令，该远程调用首先会创建一个代理对象(Proxy object)。
# 事实上，Pyro4客户端使用代理对象转发对远程对象的方法调用，并将结果传递回调用代码
server = Pyro4.Proxy("PYRONAME:server")
print(server.welcomeMessage(name))
```

- 运行

```python
# 运行一个Pyro名称服务器(name server)
python -m Pyro4.naming
# 运行服务器
python server.py
# 运行客户端
python client.py

# 依次输入信息
PYRONAME:server
LiLei
```

### 链接对象

使用Pyro4创建一个对象链，其中的对象互相调用。

![使用Pyro4链接对象](images/使用Pyro4链接对象.png)

有4个对象：1个客户端，以及按链式拓扑分布的3个服务器，如上图所示，客户端将请求转发至Server1并启动了链式调用(chain call)，后者再将请求转发至Server2.然后，它再调用链中的下一个对象Server3.当Server3再次调用Server1时，链式调用结束。

要使用Pyro4实现一个对象链，需要5个python脚本。

- client

```python
# test.py
from __future__ import print_function
import Pyro4

obj = Pyro4.core.Proxy("PYRONAME:example.chain.A")
print("Result=%s" % obj.process(["hello"]))
```

- server

每个服务器中都有一个明显的参数this以及一个next参数，前者在对象链中表示自身，后者定义了链中的下一个服务器(this后面的那个服务器)

Server_1

```python
# server_1.py
from __future__ import print_function
import Pyro4
import chainTopology


this = "1"
next = "2"

servername = "example.chainTopology." + this

daemon = Pyro4.core.Daemon()
obj = chainTopology.Chain(this, next)
uri = daemon.register(obj)
ns = Pyro4.naming.locateNS()
ns.register(servername, uri)

# 进入服务循环
print("server_%s started " % this)
daemon.requstLoop()
```

Server_2

```python
# server_2.py
from __future__ import print_function
import Pyro4
import chainTopology


this = "2"
next = "3"

servername = "example.chainTopology." + this

daemon = Pyro4.core.Daemon()
obj = chainTopology.Chain(this, next)
uri = daemon.register(obj)
ns = Pyro4.naming.locateNS()
ns.register(servername, uri)

# 进入服务循环
print("server_%s started " % this)
daemon.requstLoop()
```

Server_3

```python
# server_3.py
from __future__ import print_function
import Pyro4
import chainTopology


this = "3"
next = "1"

servername = "example.chainTopology." + this

daemon = Pyro4.core.Daemon()
obj = chainTopology.Chain(this, next)
uri = daemon.register(obj)
ns = Pyro4.naming.locateNS()
ns.register(servername, uri)

# 进入服务循环
print("server_%s started " % this)
daemon.requstLoop()
```

chain对象

```python
# chainTopology.py
from __future__ import print_function
import Pyro4


class Chain(object):
    def __init__(self, name, next):
        self.name = name
        self.nextName = next
        self.next = None

    def process(self, message):
        if self.next is None:
            self.next = Pyro4.core.Proxy("PYRONAME:example.chain." + self.nextName)
        if self.name in message:
            print("Back at %s; the chain is closed!" % self.name)
            return ["complete at " + self.name]
        else:
            print("%s forwarding the message to the object %s" % (self.name, self.nextName))
            message.append(self.name)
            result = self.next.process(message)
            result.insert(0, "passed on from " + self.name)
            return result
```

- 运行

```python
# Pyro4名称服务器

```


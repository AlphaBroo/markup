[TOC]

# 异步IO概念

```
CPU的速度远远快于磁盘、网络等IO。在一个线程中，CPU执行代码的速度极快，然而，一旦遇到IO操作，如读写文件、发送网络数据时，就需要等待IO操作完成，才能继续进行下一步操作。这种情况称为同步IO。

在IO操作的过程中，当前线程被挂起，而其他需要CPU执行的代码就无法被当前线程执行了。

因为一个IO操作就阻塞了当前线程，导致其他代码无法执行，所以我们必须使用多线程或者多进程来并发执行代码，为多个用户服务。每个用户都会分配一个线程，如果遇到IO导致线程被挂起，其他用户的线程不受影响。

多线程和多进程的模型虽然解决了并发问题，但是系统不能无上限地增加线程。由于系统切换线程的开销也很大，所以，一旦线程数量过多，CPU的时间就花在线程切换上了，真正运行代码的时间就少了，结果导致性能严重下降。

由于我们要解决的问题是CPU高速执行能力和IO设备的龟速严重不匹配，多线程和多进程只是解决这一问题的一种方法。

另一种解决IO问题的方法是异步IO。当代码需要执行一个耗时的IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时，再通知CPU进行处理。
```

可以想象如果按普通顺序写出的代码实际上是没法完成异步IO的：

```
do_some_code()
f = open('/path/to/file', 'r')
r = f.read() # <== 线程停在此处等待IO操作结果
# IO操作完成后线程才能继续执行:
do_some_code(r)
```

所以，同步IO模型的代码是无法实现异步IO模型的。

异步IO模型需要一个消息循环，在消息循环中，主线程不断地重复“读取消息-处理消息”这一过程：

```
loop = get_event_loop()
while True:
    event = loop.get_event()
    process_event(event)
```

消息模型其实早在应用在桌面应用程序中了。一个GUI程序的主线程就负责不停地读取消息并处理消息。所有的键盘、鼠标等消息都被发送到GUI程序的消息队列中，然后由GUI程序的主线程处理。

由于GUI线程处理键盘、鼠标等消息的速度非常快，所以用户感觉不到延迟。某些时候，GUI线程在一个消息处理的过程中遇到问题导致一次消息处理时间过长，此时，用户会感觉到整个GUI程序停止响应了，敲键盘、点鼠标都没有反应。这种情况说明在消息模型中，处理一个消息必须非常迅速，否则，主线程将无法及时处理消息队列中的其他消息，导致程序看上去停止响应。

消息模型是如何解决同步IO必须等待IO操作这一问题的呢？当遇到IO操作时，代码只负责发出IO请求，不等待IO结果，然后直接结束本轮消息处理，进入下一轮消息处理过程。当IO操作完成后，将收到一条“IO完成”的消息，处理该消息时就可以直接获取IO操作结果。

在“发出IO请求”到收到“IO完成”的这段时间里，同步IO模型下，主线程只能挂起，但异步IO模型下，主线程并没有休息，而是在消息循环中继续处理其他消息。这样，在异步IO模型下，一个线程就可以同时处理多个IO请求，并且没有切换线程的操作。对于大多数IO密集型的应用程序，使用异步IO将大大提升系统的多任务处理能力。

# 协程

```
协程，又称微线程，纤程。英文名Coroutine。

协程是python个中另外一种实现多任务的方式，只不过比线程更小占用更小执行单元（理解为需要的资源）。类似CPU中断，可由用户调度，可在一个子程序内中断去执行其他的子程序。 为啥说它是一个执行单元，因为它自带CPU上下文。这样只要在合适的时机，我们可以把一个协程切换到另一个协程。只要这个过程中保存或恢复 CPU上下文那么程序还是可以运行的。

通俗的理解：在一个线程中的某个函数，可以在任何地方保存当前函数的一些临时变量等信息，然后切换到另外一个函数中执行，注意不是通过调用函数的方式做到的，并且切换的次数以及什么时候再切换到原来的函数都由开发者自己确定
```

进程、线程、协程差异

```
进程是资源分配的单位
进程切换需要的资源很最大，效率很低

线程是操作系统调度的单位
线程切换需要的资源一般，效率一般（在不考虑GIL的情况下）

协程切换任务资源很小，效率高
多进程、多线程根据cpu核数不一样可能是并行的，但是协程是在一个线程中 所以是并发

由于协程在一个线程内执行，因此对于多核CPU平台，当并发量很大时，可以使用多进程+协程的方式。
```

协程概念

```
协程有两种含义：
1.用来定义写成的函数，亦可称为协程函数
2.调用协程函数的得到协程对象，表示一个最终会完成的计算或者IO操作

协程的引入使得编写单线程并发代码称为可能，事件循环在单个线程中运行并在同一个线程中执行所有的回调函数和任务，当事件循环中正在运行一个任务时，该线程中不会再同时运行其他任务，一个事件循环在某个时刻只运行一个任务。但是如果该任务执行yield from语句等待某个Future对象的完成，则当前任务被挂起，事件循环执行下一个任务。当然，不同线程中的事件循环可以并发执行多个任务

在语法形式上，协程可以通过async def语句或生成器来实现，若不需要考虑和旧版本python兼容，则优先考虑前者；基于生成器的协程函数需要使用@asyncio.coroutine进行修饰，并且使用yield from而不是yield语句

Future类代表可代哦用对象的异步执行，Task类是Future的子类，用来调度协程，负责在事件循环中执行协程对象，若果在协程中使用yield from语句从一个Future对象中返回值的话，Task对象会挂起协程的执行并且等待Future对象的完成，当Future对象完成后，协程会重新启动并得到Future对象的结果或异常

于普通函数不同，调用一个协程函数并不会立刻启动代码的执行，返回的协程对象在被调度之前不会做什么事情。启动协程对象的执行有两种方法：1.在一个正在运行的协程中使用await或yield from语句等待线程对象的返回结果；2.使用ensure_future()函数或者AbstractEventLoop.create_task()方法创建任务(Task对象)并调度协程的执行
```

## yield

Python对协程的支持是通过generator实现的。

在generator中，我们不但可以通过`for`循环来迭代，还可以不断调用`next()`函数获取由`yield`语句返回的下一个值。

但是Python的`yield`不但可以返回一个值，它还可以接收调用者发出的参数。

传统的生产者-消费者模型是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。

如果改用协程，生产者生产消息后，直接通过`yield`跳转到消费者开始执行，待消费者执行完毕后，切换回生产者继续生产，效率极高：

```python
def consumer():
    r = ''
    while True:
        n = yield r
        if not n:
            return
        print('[CONSUMER] Consuming %s...' % n)
        r = '200 OK'

def produce(c):
    # 启动生成器
    c.send(None)
    n = 0
    while n < 5:
        n = n + 1
        print('[PRODUCER] Producing %s...' % n)
        # 切换到consumer()函数执行
        r = c.send(n)
        print('[PRODUCER] Consumer return: %s' % r)
    c.close()

c = consumer()
produce(c)
```

注意到`consumer`函数是一个`generator`，把一个`consumer`传入`produce`后：

1. 首先调用`c.send(None)`启动生成器；
2. 然后，一旦生产了东西，通过`c.send(n)`切换到`consumer`执行；
3. `consumer`通过`yield`拿到消息，处理，又通过`yield`把结果传回；
4. `produce`拿到`consumer`处理的结果，继续生产下一条消息；
5. `produce`决定不生产了，通过`c.close()`关闭`consumer`，整个过程结束。

整个流程无锁，由一个线程执行，`produce`和`consumer`协作完成任务，所以称为“协程”，而非线程的抢占式多任务。

## greenlet

为了更好使用协程来完成多任务，python中的greenlet模块对其封装，从而使得切换任务变的更加简单

- 安装

```
sudo pip3 install greenlet
```

- 使用

```
#coding=utf-8

from greenlet import greenlet
import time

def test1():
    while True:
        print ("---A--")
        gr2.switch()
        time.sleep(0.5)

def test2():
    while True:
        print ("---B--")
        gr1.switch()
        time.sleep(0.5)

gr1 = greenlet(test1)
gr2 = greenlet(test2)

#切换到gr1中运行
gr1.switch()
```

## gevent

python还有一个比greenlet更强大的并且能够自动切换任务的模块`gevent`

其原理是当一个greenlet遇到IO(指的是input output 输入输出，比如网络、文件操作等)操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。

由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO

**安装**

```
pip3 install gevent
```

**使用**

- 依次运行

```
import gevent

def f(n):
    for i in range(n):
        print(gevent.getcurrent(), i)

g1 = gevent.spawn(f, 5)
g2 = gevent.spawn(f, 5)
g3 = gevent.spawn(f, 5)
g1.join()
g2.join()
g3.join()
```

- 切换执行

```
import gevent

def f(n):
    for i in range(n):
        print(gevent.getcurrent(), i)
        #用来模拟一个耗时操作，注意不是time模块中的sleep
        gevent.sleep(1)

g1 = gevent.spawn(f, 5)
g2 = gevent.spawn(f, 5)
g3 = gevent.spawn(f, 5)
g1.join()
g2.join()
g3.join()
```

- 打补丁

```
from gevent import monkey
import gevent
import random
import time

# 有耗时操作时需要
# 将程序中用到的耗时操作的代码，换为gevent中自己实现的模块
monkey.patch_all()  


def coroutine_work(coroutine_name):
    for i in range(10):
        print(coroutine_name, i)
        time.sleep(random.random())

gevent.joinall([
        gevent.spawn(coroutine_work, "work1"),
        gevent.spawn(coroutine_work, "work2")
])
```

**并发下载**

```
from gevent import monkey
import gevent
import urllib.request

# 有耗时操作时需要
monkey.patch_all()

def my_downLoad(url):
    print('GET: %s' % url)
    resp = urllib.request.urlopen(url)
    data = resp.read()
    print('%d bytes received from %s.' % (len(data), url))

gevent.joinall([
        gevent.spawn(my_downLoad, 'http://www.baidu.com/'),
        gevent.spawn(my_downLoad, 'http://www.itcast.cn/'),
        gevent.spawn(my_downLoad, 'http://www.itheima.com/'),
])
```

**多视频下载**

```
from gevent import monkey
import gevent
import urllib.request

#有IO才做时需要这一句
monkey.patch_all()

def my_downLoad(file_name, url):
    print('GET: %s' % url)
    resp = urllib.request.urlopen(url)
    data = resp.read()

    with open(file_name, "wb") as f:
        f.write(data)

    print('%d bytes received from %s.' % (len(data), url))

gevent.joinall([
        gevent.spawn(my_downLoad, "1.mp4", 'http://oo52bgdsl.bkt.clouddn.com/05day-08-%E3%80%90%E7%90%86%E8%A7%A3%E3%80%91%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%EF%BC%89.mp4'),
        gevent.spawn(my_downLoad, "2.mp4", 'http://oo52bgdsl.bkt.clouddn.com/05day-03-%E3%80%90%E6%8E%8C%E6%8F%A1%E3%80%91%E6%97%A0%E5%8F%82%E6%95%B0%E6%97%A0%E8%BF%94%E5%9B%9E%E5%80%BC%E5%87%BD%E6%95%B0%E7%9A%84%E5%AE%9A%E4%B9%89%E3%80%81%E8%B0%83%E7%94%A8%28%E4%B8%8B%29.mp4'),
])
```

# concurrent.futures

`concurrent.futures`模块提供了异步执行的高级接口，可以通过`ThreadPoolExecutor`实现线程的异步执行，也可以通过`ProcessPoolExecutor`实现进程的异步执行，都继承自抽象类`Exector`,提供了相同的接口

方法

```python
submit(fn, *args, **kwargs)
# 用来调度可调用对象fn并为其传递参数args和kwargs，返回一个Future对象
map(func, *iterables, timeout=None, chunksize=1)
# 是与内置函数map(func, *iterables)等价的异步执行方法，多个func的调用可以并发执行
shutdown(wait=True)
# 通知Executor对象执行完当前Future对象之后释放所有资源，若参数wait为True，则shutdown()方法等待执行结束并释放有关资源之后再返回，否则立即返回
```

批量移动文件

```python
from concurrent.futures import ThreadPoolExecutor
from shutil import copy
from os import listdir
from os.path import isfile, json

with ThreadPoolExecutor(max_workers=4) as e:
    for f in (fn for fn in lisdir('C:\\test')):
        src = json('C:\\test', f)
        if isfile(src):
            # 目标文件夹存在
            dst = join('D:\\test', f)
            e.submit(copy, src, dst)
```

批量快速判断素数

```python
from concurrent.futures import ProcessPoolExecutor

PRIMES = [109999999, 108376355, 1276544678, 123555677, 234645542424]
def isPrime(n):
    if n%2 == 0:
        return False
    for i in range(3, int(n**0.5)+1, 2):
        if n%i == 0:
            return False
    return True

def main():
    with ProcessPoolExecutor() as executor:
        for number, prime in zip(PRIMES, executor.map(isPrime, PRIMES)):
            print('%d is prime: %s' % (number, prime))

if __name__ == "__main__":
    main()
```

# asyncio

Python 3.4版本引入的标准库asyncio，以生成器对象为基础，直接内置了对异步IO的支持。Python 3.5又提供了语法`async`和`await`层面的支持，可以让coroutine的代码更简洁易读。

## 概述

相关概念

| 概念        | 说明                                                         |
| ----------- | ------------------------------------------------------------ |
| event_loop  | 事件循环，程序开启一个无限循环，开发者把一些函数注册到事件循环中，当满足事件发生的条件时，调用相应的协程函数 |
| coroutine   | 协程对象，指一个使用async关键字定义的函数，它的调用不会立即执行函数，而是返回一个协程对象。协程对象需要注册到事件循环中，由事件循环调用 |
| task        | 任务，一个协程对象就是一个原生可以挂起的函数，任务则是对协程进一步的封装，其中包含任务的各种状态 |
| future      | 代表将来执行或没有执行任务的结果，与task没有本质的区别       |
| async/await | python3.5用于定义协程的关键字，async定义一个协程，await用于挂起阻塞的异步调用接口 |

python3.4与python3.5区别

```
用asyncio提供的@asyncio.coroutine可以把一个generator标记为coroutine类型，然后在coroutine内部用yield from调用另一个coroutine实现异步操作。

请注意，async和await是针对coroutine的新语法，要使用新的语法，只需要做两步简单的替换：

1. @asyncio.coroutine <==> async；
2. yield from <==> await。


# python3.4
@asyncio.coroutine
def hello():
   print("Hello world!")
   r = yield from asyncio.sleep(1)
   print("Hello again!")

# python3.5
async def hello():
    print("Hello world!")
    r = await asyncio.sleep(1)
    print("Hello again!")
```

`asyncio`的编程模型就是一个消息循环。我们从`asyncio`模块中直接获取一个`EventLoop`的引用，然后把需要执行的协程扔到`EventLoop`中执行，就实现了异步IO。

异步操作需要在`coroutine`中通过`yield from`完成；多个`coroutine`可以封装成一组Task然后并发执行。

## 事件循环

大多数异步应用程序实现异步的机制时通过在后台执行的事件循环。当代码需要执行时，这些代码才会被注册到事件循环中。几乎所有的服务器都是一个事件循环。

将一个函数注册到事件循环会导致它变成一个任务。事件循环负责在获得任务后，马上执行它。另一种方式是事件循环有时在等待一定时间后，再执行任务

- 创建循环

在大多数情况下，并不需要自己创建一个事件循环对象。可以通过`asyncio.get_event_loop()`函数返回一个BaseEventLoop对象。实际上，获得的是一个子类，具体是哪个子类会根据平台的不同而不同，不必过多考虑细节。所有平台的API相同，但在某些平台上会有功能限制

```python
import asyncio

loop = asyncio.get_event_loop()
loop.is_runing()  # False,第一次获得循环对象，其并未执行
```

- 执行循环

下面的事件循环还没有注册任何内容，但可以执行它

```python
loop.run_forever()
```

若执行上述代码，将失去对python解释器的控制权，程序陷入了死循环。使用Ctrl+C来结束循环重新获得解释器的控制权。对于大多数应用程序来说，编写一个服务或者守护程序的目的获取是在前台执行，并等待其他进程发起命令，所以死循环并不是一个大障碍。但是在测试或实验中，应避免陷入死循环。

- 注册任务并执行循环

任务主要适用call_soon注册到循环，注册顺序是FIFO(先进先出)队列

```python
import functools

def hello_word():
	print('Hello word!')
    
def stop_loop(loop):
    print('Stopping loop.')
    loop.stop()

# 注册任务
loop.call_soon(hello_word)  
loop.call_soon(functools.partial(stop_loop, loop))
# 执行循环
loop.run_forever()
```

- 延迟调用

call_later方法接受延迟时间(秒)和被调用的函数名称作为参数，注册一个延迟执行的任务

```python
# 注册延时调用任务
loop.call_later(10, hello_word)
loop.call_later(20, functools.partial(stop_loop, loop))
# 执行循环
loop.run_forever()
```

若是在同一时间出现多个延时调用，先后顺序无法确定

- 偏函数

大多数接受函数的asyncio方法仅仅接受函数对象(或被其他调用元素)，但这些函数在被调用时没有带参数。若需参数，则用functools.partial，此方法本身接受参数与关键字参数，在底层函数被调用时传给底层函数

通常可以将这类调用封装到不需要参数的函数中，但是之所以要用partial，主要由于调试时更有用。Partial对象知道调用函数用的哪个参数，partial函数以数据的形式表示参数，在被调用时使用这些数据执行合适的函数调用

创建一个partial函数，查看其底层函数与参数找出函数与便函数之间区别

```python
>>>partial = functools.partial(stop_loop, loop)
>>>partial.dunc  # <function stop_loop at xxx>
>>>partial.args  # (<asyncio.unix_events._UnixSelectorEventLoop object at xxx>)
```

- 任务结束前执行循环

```python
# 装饰器将普通的python函数转换为一个协程
@asyncio.coroutine
def trivial():
    return 'Hello world!'

# 调用run_until_complete时，将任务注册并在任务结束前执行循环
# 由于该任务时队列中唯一任务，完成后退出循环，返回任务结果
loop.run_until_complete(trivial())
```

- 执行一个后台循环

```python
import asyncio
import threading

def run_loop_forever_in_background(loop):
    def thread_func(l):
        asyncio.set_event_loop(l)
        l.run_forever()
    thread = threading.Thread(target=thread_func, args=(loop,))
    thread.start()
    return thread

loop = asyncio.get_event_loop()
run_loop_forever_in_background(loop)  # <Thread(Thread-1, started xxx)>
loop.is_running()  # True
```

该例可做测试但不会应用在项目中，原因：停止循环很难，loop.stop将不再生效

```python
# 把任务注册到循环并令其立刻执行
# call_soon_threadsafe方法用于通知循环立刻异步执行给定函数，由于很少会利用线程执行事件循环，故大多情况下仅仅call_soon函数就够了，返回一个Handle对象。该对象只有一个方法:cancel,在合适时，完全可以取消任务
loop.call_soon_threadsafe(functools.partial(print, 'Hello word'))
```

## 协程

在asyncio中使用的大多数函数都是协程(coroutines)。协程师一种设计用在事件循环中执行的特殊函数。此外，若创建了协程但未执行它，那么将会在日志中记录一个错误.

```python
# python3.4中通过@asyncio.coroutine将一个函数装饰为协程
import asyncio

@asyncio.coroutine
def coro_sum(*args):
    anser = 0
    for i in args:
        answer += i
    return answer

loop = asyncio.get_event_loop()
loop.run_until_complete(coro_sum(1, 2, 3, 4, 5))  # 15
```

创建的coro_sum函数不再是一个普通的函数，而是一个协程，由事件循环调用。注意：不能再以常规方式调用该函数并返回预期结果

```python
>>>coro_sum(1, 2, 3, 4, 5)  # <generator object coro at xxx>
```

协程实际上时一个由事件循环消费的特殊生成器，这也是为什么run_until_complete方法可以接受的参数看起来像一个标准函数调用的原因所在。函数此时实际并未执行。由事件循环消费生成器，并最终返回结果

```python
# 底层实际看起来类似如下代码
try:
    next(coro_sum(1, 2, 3, 4, 5))
except StopIteration as ex:
	ex.value
```

 生成器并未返回任何值，而是立刻引发了StopIteration异常。StopIteration被赋予函数的返回值，然后事件循环可以提取该值并正确处理该值

- 嵌套的协程

协程提供了一种以模仿顺序编程的方式来调用其他携程的特殊机制(Future实例)。通过使用yield from，一个携程可以执行另外一个协程，并由语句返回结果。这是一种以顺序方式编写异步代码的可用机制

```python
import asyncio

@asyncio.coroutine
def nested(*args):
    print('The "nested" function ran with args: %r' % (args,))
    return [i+1 for i in args]

@asyncio.coroutine
def outer(*args):
    print('The "outer" function ran with args: %r' % (args,))
    # outer协程遇到yield from时挂起，将nested的协程放入事件循环并执行。outer协程在nested完成并返回结果之前不会继续执行
    # yield from语句返回它执行协程的结果
    answer = yield from nested(*[i*2 for i in args])
    return answer

loop = asyncio.get_event_loop()
loop.run_until_complete(outer(2, 3, 5, 8))
```

## Future、Task

由于使用asyncio完成的大多工作都是异步的，因此在处理异步方式执行哈书的返回值要小心。为此，yield from语句提供了一种方式，但是另外一些时候需要其他处理方式，比如，需要并行执行异步函数

- Future对象

在遇到特殊问题时一种对应机制是使用Future对象。本质上讲，Future是一个用于通知异步函数状态的对象。这包括函数的状态(执行中、已完成、已取消)，还包括函数的结果，或者是当函数引发异常时，返回对应的异常和回溯

Future是一个独立的对象，并不依赖正在执行的函数。该对象仅仅用于存储状态和结果信息，此外无它用

- Task对象

Task对象是Future对象的子类，在使用asyncio时常用的对象。每当一个协程在事件循环中被安排执行后，协程就会被一个Task对象包装。因此，在之前的示例中，当调用run_until_complete并传递一个协程时，该协程会被包装到一个Task对象中并执行。Task对象的任务时存储结果并为yield from语句提供值

run_until_complete方法并不是将一个协程包装到类中的唯一方式(甚至不是主要方式)。毕竟在很多程序中，事件循环一直在执行。在这类系统中将协程放入事件循环的方法时asyncio.async，返回对应的Task对象

注意：若是python3.4.4以上版本，使用ensure_future，若是3.4.3使用asyncio

```python
import asyncio

@asyncio.coroutine
def make_tea(variety):
    print('Now making %s tea.' % variety)
    # 获取事件循环
    asyncio.get_event_loop().stop()
    return '%s tea' % variety

# 将任务注册到事件循环，但循环未执行
task = asyncio.async(make_tea('chamomile'))
# 查看Task对象
task.done()  # False
task.result()  # 抛出InvalidStateError异常
# 开始循环，任务完成后，由于调用loop.stop()，task将立即停止执行
loop = asyncio.get_eventloop()
loop.run_forever()
# 查看Task对象
task.done()  # True
task.result()  # 'chamomile tea'
```

## 回调

Future对象(以及Task对象，因为Task是Future的子类)的另一个功能是能够将回调注册到Future。回调就是一个在Future完成后执行的一个函数(协程)，该函数接受Future作为参数

在某种程度上，回调代表了一个与yield from模型相反的模型。当一个协程使用yield from时，该协程会确保嵌套协程在其之前或同时被执行。当注册一个回调时，顺序则相反。回调被附加到原始的任务，它在任务执行之后再执行回调

可以使用对象的`add_done_callback`方法将一个回调添加到任何Future对象。回调接受一个参数，即为Future对象本身(该对象包含状态和结果信息，若存在底层任务，则为底层任务的状态或结果)

```python
import asyncio

loop = asyncio.get_event_loop()
# 生成协程，本协程不会停止
@asyncio.corountine
def make_tea(variety):
    print('Now making %s tea.' % variety)
    return '%s tea' % variety

# 该函数接受被注册到其中的Future对象(本例中是task变量)，Future对象包含协程的结果
def confirm_tea(future):
    print('The %s is made.' % future.result())
    
task = asyncio.async(make_tea('green'))
# 将confirm_tea方法作为回调赋值给task，该函数被赋值给task(对一个协程的特殊调用),而不是赋值给协程本身
# 若用调用同一个协程的asyncio.async方法将另一个任务注册到循环，该任务不会得到该回调
task.add_done_callback(confirm_tea)

loop.run_until_complete(task)  
# Now making green tea. 
# The green tea is made.
# 'green tea'
```

- 不保证成功

Future仅仅是被执行，但并不能保证它能够执行成功。本例仅仅是假设`future.result()`结果值被正确返回，但事实可能并非如此。Task的执行可能会引发异常，在这种情况下，尝试访问`future.result()`将会引发该异常

同样地，也有可能取消任务(使用`FUture.cancel()`方法或其他方式)。若这么做，则任务会被标记为Cancelled，会安排回调。在这种情况下，尝试访问`future.result()`将会引发CancelledError异常

- 幕后

在内部，由aysncio通知Future对象已经完成。Future对象接受接下来对所有已注册到Future的回调，并对其调用`call_soon_threadsafe`函数

需要注意的是，对于回调并不能保证执行顺序，完全有可能(且不会引起问题)将多个回调注册到一个任务中。然而，无法控制是否只执行某些回调以及回调之间的执行顺序

- 带参数的回调

回调系统的一个限制是回调接收作为位置参数的Future对象，但不接收其他参数

可以通过使用`functools.partial`函数将其他参数发送给回调。但若这样做，回调必须仍然接受作为位置参数的Future。实际上，在回调被调用之前，Future会附加到位置参数列表的结尾处

```python
# 接受其他参数的回调
import asyncio
import functools

loop = asyncio.get_event_loop()

@asyncio.coroutine
def make_tea(variety):
    print('Now making %s tea.' % variety)
    return '%s tea' % variety

# 接受两个位置参数
def add_ingredient(ingredient, future):
    print('Now adding %s to the %s.' % (ingredient, future.result()))
    
task = asyncio.async(make_tea('herbal'))
# 回调的注册方式是通过实例化一个带有位置参数的functools.partial对象实现
# partial仅接受一个参数，Future对象作为最后一个位置参数被发送
task.add_done_callback(functools.partial(add_ingredient, 'honey'))

loop.run_until_complete(task)  
# Now making herbal tea.
# Now adding honey to the herbal tea.
# 'herbal tea'
```

## 任务聚合

asyncio模块提供了一种聚合任务的便利方法，聚合任务主要归因于两个原因。1是在一组任务中的任何任务完成后采取某些行动。2是在所有任务都完成后采取某些行动

- 聚集任务

asyncio为聚集任务目的提供的第一种机制是通过gather函数。gather哈书接受一系列协程或任务，并返回将那些任务聚合后的单个任务(包装其接收的任何适用协程)

```python
import asyncio

loop = asyncio.get_event_loop()

@asyncio.cotoutine
def make_tea(variety):
    print('Now making %s tea.' % variety)
    return '%s tea' % variety

# 接收3个协程对象，在该函数中将所有协程包装到一个任务中，并返回一个充当3个携程聚合的单独任务
# meta_task对象高效地对3个被聚集的任务进行调度，一旦开始执行循环，3个子任务全部开始执行
meta_task = asyncio.gather(
	make_tea('chamomile'),
    make_tea('green'),
    mkae_tea('herbal')
)

meta_task.done()  # False

# asyncio.gather创建的任务，返回的结果是一个列表，该列表包含被聚集的单个任务的结果。返回的列表汇总任务的顺序保证于任务聚集的顺序一致(但任务的执行并不保证按照该顺序执行)。因此，返回的字符串列表与在asyncio.gather调用中协程的注册顺序保持一致
loop.run_until_complete(meta_task)
# Now mkaing chamomile tea
# Now mkaing herbal tea
# Now mkaing green tea
# ['chamomile tea', 'herbal tea', 'green tea']

meta_task.done()  # True
```

asyncio.gather还提供了针对作为整体的一组任务添加回调的机制，而不是针对每一个单独对象添加回调。若只想在所有任务完成后执行一次回调，但不关心任务完成的顺序，可以如下所做

```python
import asyncio

loop = asyncio.get_event_loop()

@asyncio.coroutine
def make_tea(variety):
    print('Now making %s tea.' % variety)
    return '%s tea' % variety

# 函数接受的Future对象是meta_task,而不是单个任务。
# result方法返回的是这两个任务返回值连接后的列表
def mix(future):
    print('Mixing the %s together.' % ' and '.join(future.result()))
    
meta_task = asyncio.gather(make_tea('herbal'), make_tea('green'))
meta_task.add_done_callback(mix)

loop.run_until_complete(meta_task)
# Now making green tea.
# Now making herbal tea.
# Mixing the green tea and herbal tea together.
# ['green tea', 'herbal tea']
```

- 等待任务

asyncio模块提供的另一个工具是内置的wait协程。asyncio.wait协程接受一系列协程或任务(在任务中包装任意协程)，一旦完成后就返回结果。注意该协程的签名与asyncio.gather不同。每一个协程或任务都是gather的一个单独位置参数，而wait接受一个列表作为参数

wait接受一个用于在任何任务完成后返回的参数，而无须等待所有任务完成。无论该标记位是否设置，wait方法总是返回两部分：第一个元素为一完成的Future对象；第二个元素为还未完成的部分

```python
# 类似之前asycio.gather
import asyncio

loop = asyncio.get_event_loop()

@asyncio.coroutine
def make_tea(variety):
    print('Now making %s tea.' % variety)
    return '%s tea' % variety

# wait方法返回一个协程，该协程带有值，可以在yield from中使用该协程
# 无法将回调直接附加到wait返回的协程上，若希望如此，则必须使用asyncio.async将该协程包装到一个任务中
coro = asyncio.wait([make_tea('chamomile'), make_tea('herbal')])

# asyncio.wait的返回值是一个包含Future对象(其自身包含返回值)的两部分容器。
# Future对象被重新组织，asyncio.wait协程江其分为两部分，一部分是已经完成的，另一部分是还未完成的，由于集合自身是一个未排序的结构，这意味着必须依赖Future对象来找出哪一个结果与哪一个任务对应
loop.run_until_complete(coro)
# Now making chamomile tea.
# Now making herbal tea.
# ({Task(<coro>)<result='herbal tea'>, Task(<coro>)<result='chamomile tea'>}, set())
```

> 超时

可以使用asyncio.wait协程在指定时间后返回结果，无论所有任务是否都已完成。为此，将timeout关键字参数传递给asyncio.wait

```python
import asyncio

loop = asyncio.get_event_loop()

# asyncio.sleep提供一个协程。该协程仅仅等待指定的秒数，然后返回None
# 在本例中超时时间设置使得其中一个任务在超时之前完成(第二个任务)，而另一个任务无法完成
# 使用timeout并不需要等到指定的超时时间过后才完成，若在超时时间到达之前所有的任务都执行完成，则协程江辉立刻完成
coro = asyncio.wait([asyncio.sleep(5), asyncio.sleep(1)], timeout=3)

# 两部分中的第二个元组现在包含一个未完成的任务；未完成的sleep协程仍然处于挂起状态，另一个已完成的协程又一个返回值(None)
loop.run_until_complete(coro)
# ({Task(<sleep><result=None>)}, {Task(<sleep>)<PENDING>})
```

> 等待任意任务

asyncio.wait的一个重要功能是可以在其包含的任意Future对象完成后，即可返回协程。asyncio.wait函数还接受一个return_when关键字参数。通过给该关键字传递一个特殊常量(asyncio.FIRST_COMPLETED)，一旦任意任务完成后，即可完成该协程，不再需要等所有任务都完成

```python
import asyncio

loop = asyncio.get_event_loop()

# wait的第一个参数是asyncio.sleep协程列表，当代协程被调用时，会执行所有其包含的任务。只等待1秒的asyncio.sleep协程首先执行完成，从而使得wait协程完成，因此，返回两部分结果集，其中第一部分结果集只包含一个项(已完成的任务)，第二个结果集包含两个项(仍然挂起的任务)
coro = asyncio.wait([
    asyncio.sleep(3),
    asyncio.sleep(2),
    asyncio.sleep(1)
], return_when=asyncio.FIRST_COMPLETED)

loop.run_until_complete(coro)
# ({Task(<sleep>)<result=None>},{Task(<sleep>)<PENDING>},{Task(<sleep>)<PENDING>})
```

> 等待异常

也可以使得在一个任务引发异常，而不是正常完成时，对于asyncio.wait的调用已经完成，在希望尽早补货并处理异常的情况下，这时很有价值的工具

可以使用return_from关键字参数出发该行为，但是这次使用asyncio.FIRST_EXCEPTION常量

```python
import asyncio

loop = asyncio.get_event_loop()

@asyncio.coroutine
def raise_ex_after(seconds):
    yield from asyncio.sleep(seconds)
    raise RuntimeError('Raising an exception.')
    
coro = asyncio.wait([
    asyncio.sleep(1),
    asyncio.sleep(2),
    asyncio.sleep(3),
    ], return_when=asyncio.FIRST_EXCEPTION)

# wait协程在其中一个任务引发异常后立刻停止。1秒的asyncio.sleep成功执行，因此其在返回值的第一个结果集中。raise_ex_after协程也已经完成，因此，也在第一个结果集中。然而，事实是该协程出发wait在等待3秒的协程完成之前完成，因此等待3秒的协程在第二个结果集中。
loop.run_until_complete(coro)
# ({Task(<raise_ex_after>)<exception=RuntimeError('Raising an exception.',)>, Task(<sleep>)<result=None>},{Task(<sleep>)<PENDING>})
```

有时，所有任务都不引发异常，在此情况下，就和正常情况一样，需要等待所有的任务完成后wait才完成

```python
import asyncio

loop = asyncio.get_event_loop()

coro = asyncio.wait([
    asyncio.sleep(1),
    asyncio.sleep(2),
], return_when=asyncio.FIRST_EXCEPTION)

loop.reun_until_complete(coro)
# ({Task(<sleep>)<result=NOne>, Task(<sleep>)<result=None>}, set())
```

## 队列

asyncio模块提供了一些建立在事件循环与Future对象的基本代码段之上的通用模式。其中之一是基本的队列系统队列是一个由任务执行器处理的任务集合。python生态系统包含很多第三方的任务队列工具，其中常用的一种是celery。而由asyncio模块提供的队列仅仅是最基本的队列，并不是一个全功能的队列应用程序，若需要，可以基于该基本队列按照需求进行自定义开发

Queue是asyncio的组成部分，由于：Queue类提供的方法被用于顺序或异步上下文中

```python
# Queue简单示例
import asyncio

queue = asyncio.Queue()
# 立刻从队列中添加项
queue.put_nowait('foo')
queue.qsize()  # 1
# 立刻从队列中移除项
queue.get_nowait()  # 'foo'
queue.asize()  # 0

# 若是尝试从空队列中调用get_nowait(),抛错
queue.get_nowait()  # 抛QueueEmpty异常
```

Queue类还提供了一个名称为get的方法，get方法在队列为空时并不会引发异常，而是耐心等待项被添加到队列中，然后再从队列中获得该项并立刻返回，与get_nowait不同，该方法是一个协程，在异步上下文中执行

```python
import asyncio

loop = asyncio.get_evnet_loop()

queue = asyncio.Queue()

queue.pu_nowait('foo')
# 由于队列中已经有一项，故get方法会立刻返回。若队列中没有项，则直接调用loop.run_until_complete会永远处于执行状态，并阻塞解释器
loop.run_until_complete(queue.get())  # 'foo'
```

可以使用asyncio.wait中的timeout参数来查看实际的执行情况

```python
import asyncio

loop = asyncio.get_event_loop()
queue = asyncio.Queue()

task = asyncio.async(queue.get())
coro = asyncio.wait([task], timeout=1)

loop.run_until_complete(coro)
# (set(), {Task(<get>)<PENDING>})

# 此时，队列中依然为空，因此从队列汇总获得项的任务继续执行
task.done()  # False

# 入队列一项
queue.put_nowait('bar')

# 该任务并未完成，这是由于事件循环不再处于执行状态。
# 由于任务任然注册到该事件循环上，因此将一个用于在执行完之后停止循环的回调注册到事件循环上，就可以再次启动任务
import functools

def stop(l, future):
    l.stop()
    
task.add_done_callback(functoola.partial(stop, loop))

loop.run_forever()

# 由于队列汇总已经包含一项，任务已完成，且任务的结果为队列中的项('bar')
task.done()  # True
task.result()  # 'bar'
```

- 最大队列长度

允许设置Queue对象的最大长度，在创建队列时，可以通过设置maxsize关键字参数实现这一点

```python
import asyncio

queue = asyncio.Queue(maxsize=5)
```

若设置了最大长度，Queue将不再允许入队超过最大值的项，调用put方法将会等待之前的项被移除之后(且只能是之后)将项入队。若在队列满时调用put_nowait，将会引发QueueFull异常

## 服务器

asyncio模块最常见的用处是创建一个作为守护程序的服务并接受命令。asyncio模块定义了一个Protocol类，用于在接受或失去连接时以及接收到数据时触发对应事件

此外，事件循环定义了一个create_server方法，用于打开一个socket连接，该连接允许将数据发送到事件循环并交给Protocol类

```python
import asyncio

class Shutdown(Exception):
    pass

class ServeProtocol(asyncio.Protocol):
    """"""
    def connection_made(self, transport):
        self.transport = transport
        self.write('Welecome.')
        
    def data_received(self, data):
        """接受一个数据行并尝试对该数据行进行处理。只接受两个基本命令，任何其他输入的命令都会导致错误"""
        # 语法检查，空命令时直接返回
        if not data:
            return 
        
        # 
        message = data.decode('ascii')
        command = message.strip().split(' ')[0].lower()
        args = message.strip().split(' ')[1:]
        
        # 检查命令的格式
        if not hasattr(self, 'command_%s' % command):
            self.write('Invalid command: %s' % command)
            return 
        
        # 执行命令
        try:
            return getattr(self, 'command_%s' % command)(*args)
        except Exception as ex:
            self.write('Error: %s\n' % str(ex))
            
    def write(self, msg_string):
        """用于类型转换，将文本字符串转换为字节，避免了在每次将数据写入通道时，将本文字符串转换为字节字符串"""
        string += '\n'
        self.transort.write(msg_string.encode('ascii', 'ignore'))
        
    def command_add(self, *args):
        args = [int(i) for i in args]
        self.write('%d' % sum(args))
        
    def command_shutdown(self):
        self.write('Okay. Shutting down.')
        raise KeyboardInterrupt
        
if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    # 启动服务器，并在本季的特定端口上运行
    coro = loop.create_server(ServerProtocol, '127.0.0.1', 8000)
    asyncio.async(coro)
    try:
        loop.run_forever()
    except KeyboardInterrupt:
        pass
```

## 示例

> Demo1

用`asyncio`实现`Hello world`代码如下：

```python
import asyncio

@asyncio.coroutine
def hello():
    print("Hello world!")
    # 异步调用asyncio.sleep(1):
    r = yield from asyncio.sleep(1)
    print("Hello again!")

# 获取EventLoop:
loop = asyncio.get_event_loop()
# 执行coroutine
loop.run_until_complete(hello())
# 关闭
loop.close()
```

实现过程

```
@asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。

hello()会首先打印出Hello world!，然后，yield from语法可以让我们方便地调用另一个generator。由于asyncio.sleep()也是一个coroutine，所以线程不会等待asyncio.sleep()，而是直接中断并执行下一个消息循环。当asyncio.sleep()返回时，线程就可以从yield from拿到返回值（此处是None），然后接着执行下一行语句。

把asyncio.sleep(1)看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。
```

> Demo2

我们用Task封装两个`coroutine`试试：

```python
import threading
import asyncio

@asyncio.coroutine
def hello():
    print('Hello world! (%s)' % threading.currentThread())
    yield from asyncio.sleep(1)
    print('Hello again! (%s)' % threading.currentThread())

loop = asyncio.get_event_loop()
tasks = [hello(), hello()]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
```

观察执行过程：

```
Hello world! (<_MainThread(MainThread, started 140735195337472)>)
Hello world! (<_MainThread(MainThread, started 140735195337472)>)
(暂停约1秒)
Hello again! (<_MainThread(MainThread, started 140735195337472)>)
Hello again! (<_MainThread(MainThread, started 140735195337472)>)
```

由打印的当前线程名称可以看出，两个`coroutine`是由同一个线程并发执行的。

> Demo3

如果把`asyncio.sleep()`换成真正的IO操作，则多个`coroutine`就可以由一个线程并发执行。

我们用`asyncio`的异步网络连接来获取sina、sohu和163的网站首页：

```python
import asyncio

@asyncio.coroutine
def wget(host):
    print('wget %s...' % host)
    connect = asyncio.open_connection(host, 80)
    reader, writer = yield from connect
    header = 'GET / HTTP/1.0\r\nHost: %s\r\n\r\n' % host
    writer.write(header.encode('utf-8'))
    yield from writer.drain()
    while True:
        line = yield from reader.readline()
        if line == b'\r\n':
            break
        print('%s header > %s' % (host, line.decode('utf-8').rstrip()))
    # Ignore the body, close the socket
    writer.close()

loop = asyncio.get_event_loop()
tasks = [wget(host) for host in ['www.sina.com.cn', 'www.sohu.com', 'www.163.com']]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
```

执行结果如下：

```
wget www.sohu.com...
wget www.sina.com.cn...
wget www.163.com...
(等待一段时间)
(打印出sohu的header)
www.sohu.com header > HTTP/1.1 200 OK
www.sohu.com header > Content-Type: text/html
...
(打印出sina的header)
www.sina.com.cn header > HTTP/1.1 200 OK
www.sina.com.cn header > Date: Wed, 20 May 2015 04:56:33 GMT
...
(打印出163的header)
www.163.com header > HTTP/1.0 302 Moved Temporarily
www.163.com header > Server: Cdn Cache Server V2.0
...
```

可见3个连接由一个线程通过`coroutine`并发完成。

> Demo4

```python
import asyncio, time


now = lambda: time.time()
async def func(x):
    print('Waiting for %d s' % x)
    await asyncio.sleep(x)
    return  'Done after {}s'.format(x)

start = now()

coro1 = func(1)
coro2 = func(2)
coro3 = func(3)

tasks = [
    asyncio.ensure_future(coro1),
    asyncio.ensure_future(coro2),
    asyncio.ensure_future(coro3)
]

loop = asyncio.get_event_loop()
loop.run_until_complete(asyncio.wait(tasks))

for task in tasks:
    print('Task return:', task.result())

print('Program consumes: %fs' % (now()-start))
```

执行过程

```
导入asyncio和time模块，定义一个计时的lambda表达式
通过async关键字定义一个协程函数func()，分别定义3个协程
在func()内部使用sleep模拟IO的耗时操作，遇到耗时操作，await将协程的控制权让出
定义一个tasks列表，列表中分别通过ensure_future()创建3个tasks
协程不能直接运行，需将其加入事件循环中，get_event_loop()用于创建一个事件循环
通过run_until_complete()将tasks列表加入事件循环中
通过tasks的result方法获取协程运行状态
最后计算整个程序的运行耗时
```

在单线程中使用事件循环同时计算多个整数的阶乘

```python
import asyncio

async def factorial(name, number);
    f = 1
    for i in range(2, number+1):
        print("Task %s: Compute factorial (%s)..." % (name, i))
        await asyncio.sleep(0.5)
        f *= 1
    print("Task %s: factorial (%s)=%s"%(name, number, f))
    # 返回当前上下文中实现AbstractEventLoop接口的事件循环对象
    loop = asyncio.get_event_loop()
    tasks = [
        asyncio.ensure_future(factorial("A", 14)),
        asyncio.ensure_future(factorial("B", 13)),
        asyncio.ensure_future(factorial("C", 16))
    ]
    # gather()用来返回一个从给定的协程对象或Future对象得到的聚集结果，
    # 要求所有的Future对象共享同一个事件循环，若所有的任务顺利完成，该函数返回结果列表
    loop.run_until_complete(asyncio.gather(*tasks))
    loop.close()
```

显示当前日期时间

```python
import asyncio.subprocess
import sys 

@asyncio.coroutine
def get_date():
    code = 'import datetime; print(datetime.datetime.now())'
    # 创建子进程，并把标准输出重定向道管道
    create = asyncio.create_subprocess_exec(sys.executable, '-c', code, stdout=asyncio.subprocess.PIPE)
    proc = yield from create
    # 读取一行输出
    data = yield from proc.stdout.readline()
    line = data.decode('ascii').rstrip()
    # 等待子进程退出
    yield from proc.wait()
    return line

if sys.platform == "win32":
    loop = asyncio.ProactorEventLoop()
    asyncio.set_event_loop(loop)
else:
    loop = asyncio.get_event_loop()

date = loop.run_until_complete(get_date())
print("Current date: %s" % date)
loop.close()
```

使用协程计算阶乘

```python
import asyncio
import operator
import functools

@asyncio.coroutine
def slow_operation(future, n):
    yield from asyncio.sleep(1)
    result = functools.reduce(operator.mul, range(1, n+1))
    # 设置计算结果
    future.set_result(result)

loop = asyncio.get_event_loop()
future = asyncio.Future()
# 创建并启动任务，计算50的阶乘
asyncio.ensure_future(slow_operation(future, 50))
loop.run_until_complete(future)
# 输出计算结果
print(future.result())
loop.close()
```

在事件循环中执行函数

```python
import asyncio

def hello_word(loop):
    print('hello word')
    # 结束事件循环
    loop.stop()

loop = asyncio.get_event_loop()
# 在制定的事件循环中执行函数
loop.call_soon(hello_word, loop)
# 一直运行事件循环，阻塞当前线程，直到调用loop.stop()
loop.run_forever()
loop.close()
```

# aiohttp

`asyncio`可以实现单线程并发IO操作。如果仅用在客户端，发挥的威力不大。如果把`asyncio`用在服务器端，例如Web服务器，由于HTTP连接就是IO操作，因此可以用单线程+`coroutine`实现多用户的高并发支持。

`asyncio`实现了TCP、UDP、SSL等协议，`aiohttp`则是基于`asyncio`实现的HTTP框架。

我们先安装`aiohttp`：

```
pip install aiohttp
```

然后编写一个HTTP服务器，分别处理以下URL：

- `/` - 首页返回`b'<h1>Index</h1>'`；
- `/hello/{name}` - 根据URL参数返回文本`hello, %s!`。

代码如下：

```
import asyncio

from aiohttp import web

async def index(request):
    await asyncio.sleep(0.5)
    return web.Response(body=b'<h1>Index</h1>')

async def hello(request):
    await asyncio.sleep(0.5)
    text = '<h1>hello, %s!</h1>' % request.match_info['name']
    return web.Response(body=text.encode('utf-8'))

async def init(loop):
    app = web.Application(loop=loop)
    app.router.add_route('GET', '/', index)
    app.router.add_route('GET', '/hello/{name}', hello)
    srv = await loop.create_server(app.make_handler(), '127.0.0.1', 8000)
    print('Server started at http://127.0.0.1:8000...')
    return srv

loop = asyncio.get_event_loop()
loop.run_until_complete(init(loop))
loop.run_forever()
```

注意`aiohttp`的初始化函数`init()`也是一个`coroutine`，`loop.create_server()`则利用`asyncio`创建TCP服务
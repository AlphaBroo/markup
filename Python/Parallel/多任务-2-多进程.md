[TOC]

# 多进程

## 概述

- fork

```
Unix/Linux操作系统提供了一个fork()系统调用，它非常特殊。普通的函数调用，调用一次，返回一次，但是fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。

子进程永远返回0，而父进程返回子进程的ID。
这样做的理由是，一个父进程可以fork出很多子进程，所以，父进程要记下每个子进程的ID，而子进程只需要调用getppid()就可以拿到父进程的ID。

有了fork调用，一个进程在接到新任务时就可以复制出一个子进程来处理新任务，常见的Apache服务器就是由父进程监听端口，每当有新的http请求时，就fork出子进程来处理新的http请求。

在Unix/Linux下，multiprocessing模块封装了fork()调用，使我们不需要关注fork()的细节。由于Windows没有fork调用，因此，multiprocessing需要“模拟”出fork的效果，父进程所有Python对象都必须通过pickle序列化再传到子进程去，如果multiprocessing在Windows下调用失败了，要先考虑是不是pickle失败了。
```

示例

```python
import os

print('Process (%s) start...' % os.getpid())
# Only works on Unix/Linux/Mac:
pid = os.fork()
if pid == 0:
    print('I am child process (%s) and my parent is %s.' % (os.getpid(), os.getppid()))
else:
    print('I (%s) just created a child process (%s).' % (os.getpid(), pid))
```

结果

```
Process (876) start...
I (876) just created a child process (877).
I am child process (877) and my parent is 876.
```

- multiprocessing

```
multiprocessing模块就是跨平台版本的多进程管理模块，可以实现多进程的程序设计
支持子进程、通信和数据共享，提供多种形式的同步机制及Process、Queue、Pipe、Lock等组件
同时支持本地并发和远程并发，有效避免了全局解释器锁(GIL)问题，可以更有效地利用CPU资源，尤其适用于多核或多CPU环境
```

进程创建于管理模块

| 组件        | 描述                                                         |
| ----------- | ------------------------------------------------------------ |
| process     | 用于创建子进程，可以实现多进程的创建、启动、关闭等操作       |
| pool        | 用于创建管理进程池，当子进程非常多且需要控制子进程数量时使用 |
| manager     | 通常与pool一同使用，用于资源共享                             |
| pipe        | 用于进程间的管道通信                                         |
| queue       | 用于进程通信                                                 |
| value,array | 用于进程通信，资源共享                                       |

子进程同步模块

| 组件      | 描述                         |
| --------- | ---------------------------- |
| condition | 条件变量                     |
| event     | 用来实现进程间的同步通信     |
| lock      | 锁                           |
| rlock     | 多重锁                       |
| semaphore | 用来控制对共享资源的访问数量 |

## Process

multiprocessing模块提供了一个Process类来代表一个进程对象，这个对象可以理解为是一个独立的进程，可以执行另外的事情

```python
# Process创建的实例对象
Process([group [, target [, name [, args [, kwargs]]]]])
```

参数

| name   | 说明                                                     |
| ------ | -------------------------------------------------------- |
| target | 如果传递了函数的引用，可以任务这个子进程就执行这里的代码 |
| args   | 给target指定的函数传递的参数，以元组的方式传递           |
| kwargs | 给target指定的函数传递命名参数                           |
| name   | 给进程设定一个名字，可以不设定                           |
| group  | 指定进程组，大多数情况下用不到                           |

实例方法

| 方法              | 说明                                                         |
| ----------------- | ------------------------------------------------------------ |
| `is_alive`        | 返回进程是否在运行                                           |
| `join([timeout])` | 阻塞当前上下文环境的进程，直到调用此方法的进程终止或到达指定的timeout(可选参数) |
| `start()`         | 启动子进程实例(创建子进程)，进程准备就绪，等待CPU调度        |
| `run()`           | `start()`调用run方法，如果实例进程时未指定传入target,则star默认执行run方法 |
| ` terminate()`    | 不管任务是否完成，立即终止子进程                             |

属性

| 属性     | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| daemon   | 与线程setDeamon的功能一样(将父进程设置为守护进程，当父进程结束时，子进程也结束) |
| exitcode | 进程在运行时为None,如果为-N,则表示被信号N结束                |
| name     | 当前进程的别名，默认为Process-N，N为从1开始递增的整数        |
| pid      | 当前进程的进程号                                             |

### 创建进程

创建一个进程

```python
from multiprocessing import Process
import os

# 子进程要执行的代码
def run_proc(name):
    print('Run child process %s (%s)...' % (name, os.getpid()))

if __name__=='__main__':
	# os.getpid():获取当前程序进程号
    print('Parent process %s.' % os.getpid())
    # 传入子进程函数名和参数 
    p = Process(target=run_proc, args=('test',))
    print('Child process will start.')
    # 开启子进程
    p.start()
    # 等待子进程结束
    p.join()
    print('Child process end.')
```

创建多个进程

```python
import multiprocessing
import time

def process1(interval):
	while True:
		print('process1 is runing')
		time.sleep(interval)

def process2(interval):
	while True:
		print('process2 is runing')
		time.sleep(interval)
		
if __name__ == '__main__':
	p1 = multiprocessing.Process(target = process1, args = (2,))
	p2 = multiprocessing.Process(target = process2, args = (2,))
	p1.start();
	p2.start();
	
	while True:
		for p in multiprocessing.active_children():
			print('child Process:' + p.name + '\t,id:' + str(p.id) + 'is alive')
		print('main process is running')
        time.sleep(2)
```

对进程进行命名

```python
import multiprocessing
import time


def foo():
    name = multiprocessing.current_process().name  # 获取父进程的名字
    print("Starting %s \n" % name)
    time.sleep(3)
    print("Exting %s \n" % name)
    
if __name__ == "__main__":
    process_with_name = multiprocessing.Process(name='foo_process', target=foo)  # 设定名字
    process_with_default_name = multiprocessing.Process(target=foo)
    process_with_name.start()
    process_with_default_name.start()
```

在后台运行进程

```python
import multiprocessing
import time


def foo():
    name = multiprocessing.current_process().name
    print("Starting %s \n" % name)
    time.sleep(3)
    print("Exting %s \n" % name)
    
if __name__ == "__main__":
    background_process = multiprocessing.Process(name='background_process', target=foo)
    background_process.daemon = True  # 非后台模式下的进程有输出，在主程序结束后，后台进程自动结束
    NO_background_process = multiprocessing.Process(name='NO_background_process',target=foo)
    NO_background_process.daemon = False
    background_process.start()
    NO_background_process.start()
```

杀死进程

```python
import multiprocessing
import time

def foo():
    print('Starting function')
    time.sleep(0.1)
    print('Finished function')

if __name__ == "__main__":
    p = multiprocessing.Process(target=foo)
    print('Process before execution:', p, p.is_alive())  # 监控生命周期
    p.start()
    print('Process runing:', p, p.is_alive())
    p.terminate()  # 终止进程
    print('Process terminated:', p, p.is_alive())
    p.join()
    print('Process joined:', p , p.is_alive())
    print('Process exit code: ', p.exitcode)
```

### 在子类中使用

```
定义一个新的Process类的子类
重写__init__(self [,args])方法增加额外的参数
重写run(self [,args])方法实现Process启动后需要做的事情
创建好新的Process子类后，创建一个实例，然后调用start()方法来启动，该方法会调用run()方法
```

具体实现

```python
import multiprocessing
import time

class ChildProcess(multiprocessing.Process):
	def __init__(self, interval):
        multiprocessing.Process.__init__(self)
        self.interval = interval
        
    def run(self):
        while True:
            print('ChildProcess is runing')
            time.sleep(self.interval)
            
 
if __name__ == '__main__':
    p = ChildProcess(2)
    p.start()
    while True:
        print('MainProcess is running')
        time.sleep(2)
```

## 进程池

### Pool

如果要启动大量的子进程，可以用进程池的方式批量创建子进程

Pool对象提供了大量的方法支持并行操作

```python
apply(func[, args[, kwds]])
# 调用函数func，并传递参数args和kwds，同时阻塞当前进程直至函数返回，函数func只会在进程池中的一个工作进程中运行；一直阻塞，知道结果就绪为止。

apply_async(func[, args[, kwds[, callback[, error_callback]]]])
# apply()的变形，返回结果对象，可以通过结果对象的get()方法获取其中的结果，参数callback和error_callback都是单参数函数，当结果对象可用时会自动调用callback，该调用失败时会自动调用error_callback；异步操作，并不会锁定主线程，直到所有子类都执行完毕为止。

map(func, iterable[, chunksize])
# 内置函数map()的并行版本，但只能接收一个可迭代对象作为参数，该方法会阻塞当前进程直至结果可用。该方法会把迭代对象iterable切分成多个块再作为独立的任务提交给进程池，块的大小可以通过参数chunksize(默认1)来设置

map_async(func, iterable[, chunksize[, callback[, error_callback]]])
# 与map()方法类似，但返回结果对象，需要使用结果对象的get()方法来获取其中的值。如果指定了回调，那么它就是可调用的，且会接收一个参数。当结果就绪时，回调就会使用到它(除非调用失败了)。回调应该立即执行，否则，处理结果的线程就会被阻塞住

imap(func, iterable[, chunksize[, callback[, error_callback]]])
# map()方法的惰性求值版本，返回迭代器对象

imap_unordered(func, iterable[, chunksize])
# 与imap()方法类似，但不保证结果会按参数iterable中原来元素的先后顺序返回

starmap(func, iterable[, chunksize])
# 类似于map()方法，但要求参数iterable中的元素为得带对象并可解包为函数func的参数

starmap_async(func, iterable[, chunksize[, callback[, error_back]]])
# 方法starmap()和map_async的组合，返回结果对象

close()
# 不允许再向进程池提交任务，当所有已提交任务完成后工作进程会退出

terminate()
# 立即结束工作进程，当线程池对象被回收时会自动调用该方法

join()
# 等待工作进程退出，在此之前必须先调用close()或treminate()
```

Pool对象的几种常用方法示例

```python
from multiprocessing import Pool
import time 	

def f(x):
  	print(x*x)
    time.sleep(2)
    return x*x
  
if __name__ == '__main__':
		# 定义启动的进程数量
    pool = pppl(processes=5)
    res_list = []
    for i in range(10):
      	# 以异步并行的方式启动进程，如果要同步等待的放肆，可以在每次启动进程之后调用res.get(),也可以使用pool.apply
        res = pool.apply_async(f, [i,])
        print('------', i)
        res_list.append(res)    
    pool.close()
    pool.join()
    for r in res_list:
      	print('result', r.get(timeout=5))
```

示例2

```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds.' % (name, (end - start)))

if __name__=='__main__':
    print('Parent process %s.' % os.getpid())
    # 定义一个进程池，最大进程数4
    p = Pool(4)
    for i in range(5):
    	# Pool().apply_async(要调用的目标,(传递给目标的参数元祖,))
    	# 每次循环将会用空闲出来的子进程去调用目标
        p.apply_async(long_time_task, args=(i,))
    print('Waiting for all subprocesses done...')
    p.close()	# 关闭进程池，关闭后pool不再接收新的请求
    p.join()	# 等待pool中所有子进程执行完成，必须放在close语句之后
    print('All subprocesses done.')
```

示例3


```python
from multiprocessing import Pool
import time

def f(x):
    return x*x

if __name__ == '__main__':
  	# 使用with语句
    with Pool(processes=4) as pool:
        # 返回结果对象，可以通过get()方法获取其中的值
        result = pool.apply_async(f, (10,))
        print(result.get(timeout=1))
        # 直接返回结果列表
        print(pool.map(f, range(10)))
        # 返回迭代器对象
        it - pool.imap(f, range(10))
        print(next(it))
        print(next(it))
        pritn(it.next(timeout=1))
        #  进入睡眠状态10s
        result = pool.apply_async(time.sleep,(10,))
        # 下面的代码会引发超时异常
        print(result.get(timeout=3))
```


并发计算二维数组每行的平均值

```python
from multiprocessing import Pool
from statistics import mean

def f(x):
    return mean(x)

if __name__ == '__main__':
    x = [list(range(10)), list(range(20,30)),
         list(range(50, 60)), list(range(80, 90))]
    with Pool(5) as p:  # 创建包含5个进程的进程池
        print(p.map(f,x)) # 并发运行
```

## 管理进程间的状态

### Manager

Manager对象提供了不同进程间共享数据的方式，甚至可以在网络上不同机器上运行的进程间共享数据。Manager对象控制一个拥有`list,dict,Lock,RLock,Semphore,BoundedSemaphore,Condition,Event,Barrier,Queue,Value,Array,Namespace`等对象的服务端进程，并且允许其他进程通过代理来操作这些对象

管理器拥有如下属性

```
它会控制服务端进程，该进程会管理共享对象
当有人修改共享对象时，它会确保共享对象在所有进程中都会更新
```

使用Manager对象实现进程间数据交换

```python
# 示例1
from multiprocessing import Process, Manager

def f(d, l, t):
    d['name'] = 'Li Lei'
    d['age'] = 18
    d['sex'] = 'Male'
    d['address'] = 'Yantai'
    l.reverse()
    t.value = 3

if __name__ == "__main__":
    with Manager() as manager:
        d = manager.dict()
        l = manager.list(range(10))
        t = manager.Value('i', 0)
        p = Process(target=f, args=(d,l,t))
        p.start()
        p.join()
        for item in d.items():
            print(item)
        print(1)
        print(t.value)
 
# 示例2
import multiprocessing

def worker(dictionary, key, item):
    dictionary[key] = item

if __name__ == "__main__":
    # 声明管理器
    mgr = multiprocessing.Manager()
    # 创建字典类型的数据结构
    dictionary = mgr.dict()
    jobs = [multiprocessing.Process(target=worker, args=(dictionary, i, i*2)) for i in range(10)]
    for j in jobs:
        j.start()
    for j in jobs:
        j.join()
    print('Results: ', dictionary)
```

使用Manager对象实现不同机器上的进程跨网络共享数据

```python
# 1. 编写multiprocessing_server.py,启动服务进程，创建可共享的队列对象
from multiprocessing.managers import BaseManager
from queue import Queue

q = Queue()
class QueueManager(BaseManager):
    pass
QueueManager.register('get_queue', callable=lambda:q)
m = QueueManager(address=('', 30030), authkey=b'leili')
s = m.get_server()
s.serve_forever()

# 2.编写程序文件multiprocessing_client1.py,连接服务器进程，并往共享的队列中存入一些数据
from multiprocessing.managers import BaseManager
from queue import Queue

class QueueManager(BaseManager):
    pass
QueueManager.register('get_queue')
# 假设服务器的地址是10.2.1.2
m = QueueManager(address=('10.2.1.2', 30030), authkey=b'leili')
m.connect()
q = m.get_queue()
for i in range(3):
    q.put()

# 3.编写程序文件multiprocessing_client2.py,连接服务器进程，从共享对列对象中读取数据并输出显示
from multiprocessing.managers import BaseManager
from queue import Queue


class QueueManager(BaseManager):
    pass
QueueManager.register('get_queue')
# 假设服务器的地址是10.2.1.2
m = QueueManager(address=('10.2.1.2', 30030), authkey=b'leili')
m.connect()
q = m.get_queue()
for i in range(3):
    print(q.put())
```

创建和使用自定义的Manager对象与Proxy对象

```python
from multiprocessing import freeze_support
from multiprocessing.managers import BaseManager, BaseProxy
import operator

# 普通类
class Foo:
    def f(self):
        print('you called Foo.f()')

    def g(self):
        print('you called Foo.q')

    def _h(self):
        print('you caled Foo._h()')

# 生成器
def baz():
    for i in range(10):
        yield i*i

# 生成器对象的代理类
class GeneratorProxy(BaseProxy):
    __exposed = ['__next__']
    def __iter__(self):
        return self
    
    def __next__(self):
        return self._callmethod('__next__')

# 返回operator模块的函数
def get_operator_module():
    return operator


class MyManager(BaseManager):
    pass

# 注册Foo类，默认的公开成员f()和g()可以通过代理来访问
MyManager.register('Fool', Foo)
# 注册Foo类，明确指定成员g()和_h()可以通过代理来访问
MyManager.register('Foo2', Foo, expose=('g','_h'))
# 注册生成器函数baz，指定代理类型为GeneratorProxy
MyManager.register('baz', baz, proxytype=GeneratorProxy)
# 注册函数get_operator_module()，使其可以通过代理来访问
MyManager.register('operator',get_operator_module)

def test():
    manager = MyManager()
    manager.start()
    print('-'*20)
    # 创建对象
    f1 = manager.Fool()
    # 调用对象成员
    f1.f()
    f1.g()
    # 确认对象拥有哪些可访问的成员
    assert not hasattr(f1, '_h')
    assert sorted(f1._exposed_) == sorted(['f', 'g'])
    print('-'*20)
    f2 = manager.Foo2()
    f2.g()
    f2._h()
    assert not hasattr(f2, 'f')
    assert sorted(f2._exposed_) == sorted(['g', '_h'])
    print('-'*20)
    it = manager.baz()
    for i in it:
        print('<%d>'%i, end=' ')
    print()
    print('-'*20)
    op = manager.operator()
    print('op.add(23,45)=', op.add(23, 45))
    print('op.pow(2,94)=', op.pow(2, 94))
    print('op._exposed_=', op._exposes_)


if __name__ == "__main__":
    # 支持使用py2exe,Pyinstaller和cx_Freeze打包为windows可执行程序
    freeze_support()
    test()
```

## 进程间通信

并行应用的开发需要在进程间进行数据交换。Python的`multiprocessing`模块有两个通信通道，通过它们可以管理对象的交换，分别是：Pipe管道，Queue队列

### Queue

可以通过队列数据结构来共享数据。队列会返回一个进程共享队列，它是线程与进程安全的，任何可序列对象(python使用pickable模块来序列化对象)都可以通过它进行交换

Queue对象的方法

```
初始化Queue()对象时（例如：q=Queue()），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头）
```

| 方法                                 | 说明                                                         |
| ------------------------------------ | ------------------------------------------------------------ |
| `Queue.qsize()`                      | 返回当前队列包含的消息数量                                   |
| `Queue.empty()`                      | 如果队列为空，返回True，反之False                            |
| `Queue.full()`                       | 如果队列满了，返回True,反之False                             |
| `Queue.get([block[, timeout]])`      | 获取队列中的一条消息，然后将其从列队中移除，block默认值为True；<br/>1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果为空，此时程序将被阻塞（停在读取状态），直到从消息列队读到消息为止，如果设置了timeout，则会等待timeout秒，若还没读取到任何消息，则抛出"Queue.Empty"异常；<br/>2）如果block值为False，消息列队如果为空，则会立刻抛出"Queue.Empty"异常； |
| `Queue.get_nowait()`                 | 相当Queue.get(False)                                         |
| `Queue.put(item,[block[, timeout]])` | 将item消息写入队列，block默认值为True；<br/>1）如果block使用默认值，且没有设置timeout（单位秒），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态），直到从消息列队腾出空间为止，如果设置了timeout，则会等待timeout秒，若还没空间，则抛出"Queue.Full"异常；<br/>2）如果block值为False，消息列队如果没有空间可写入，则会立刻抛出"Queue.Full"异常； |
| `Queue.put_nowait(item)`             | 相当`Queue.put(item, False)`                                 |
queue读写数据

```python
# 以Queue为例，在父进程中创建两个子进程，一个往Queue里写数据，一个从Queue里读数据
from multiprocessing import Process, Queue
import os, time, random

# 写数据进程执行的代码:
def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码:
def read(q):
    print('Process to read: %s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)

if __name__=='__main__':
    # 父进程创建Queue，并传给各个子进程：
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程pw，写入:
    pw.start()
    # 启动子进程pr，读取:
    pr.start()
    # 等待pw结束:
    pw.join()
    # pr进程里是死循环，无法等待其结束，只能强行终止:
    pr.terminate()
```

> 上下文对象context的Queue

```python
import multiprocessing as mp

def foo(q):
    q.put('hello word')

if __name__ == "__main__":
    ctx = mp.get_context('spawn')
    q = ctx.Queue()
    p = ctx.Processing(target=foo, args=(q,))
    p.start()
    print(q.get())
    p.join()
```

> 进程池中的Queue

如果要使用Pool创建进程，需要使用multiprocessing.Manager()中的Queue()，而不是multiprocessing.Queue()

```python
# 修改import中的Queue为Manager
from multiprocessing import Manager,Pool
import os,time,random

def reader(q):
    print("reader启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in range(q.qsize()):
        print("reader从Queue获取到消息：%s" % q.get(True))

def writer(q):
    print("writer启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in "itcast":
        q.put(i)

if __name__=="__main__":
    print("(%s) start" % os.getpid())
    q = Manager().Queue()  # 使用Manager中的Queue
    po = Pool()
    po.apply_async(writer, (q,))

    time.sleep(1)  # 先让上面的任务向Queue存入数据，然后再让下面的任务开始从中取数据

    po.apply_async(reader, (q,))
    po.close()
    po.join()
    print("(%s) End" % os.getpid())
```

生产者-消费者队列(mac无法运行)

```python
import multiprocessing
import random
import time


class Producer(multiprocessing.Process):
    def __init__(self, queue):
        multiprocessing.Process.__init__(self)
        self.queue = queue

    def run(self):
        for i in range(10):
            item = random.randint(0, 256)
            self.queue.put(item)
            print('Process Producer: item %d appended to queue %s' % (item, self.name))
            time.sleep(1)
            print('The size of queue is %d' % self.queue.qsize())


class Consumer(multiprocessing.Process):
    def __init__(self, queue):
        multiprocessing.Process.__init__(self)
        self.queue = queue

    def run(self):
        while True:
            if self.queue.empty():
                print('the queue is empty')
                break
            else:
                time.sleep(2)
                item = self.queue.get()
                print('Process Consumer: item %d popped by %s \n' % (item, self.name))
                time.sleep(1)


if __name__ == '__main__':
    queue = multiprocessing.Queue()
    process_producer = Producer(queue)
    process_consumer = Consumer(queue)
    process_producer.start()
    process_consumer.start()
    process_producer.join()
    process_consumer.join()
```

### Pipe

使用管道实现进程间的数据交换。管道有两个端，一个接收端和一个发送端，相当于在两个进程之间建立了一个传输数据的管道

管道会完成如下事情：返回由管道所连接的一对连接对象。每个对象都拥有send/receive方法，实现进程间通信

```python
from multiprocessing import process, Pipe

def f(conn):
    # 向管道中发送数据
    conn.send('hello world')
    # 关闭管道
    conn.close()

if __name__ == "__main__":
    # 创建管道对象
    parent_conn, child_conn = Pipe()
    # 将管道的一方作为参数传递给子进程
    p = Process(target=f, args=(child_conn,))
    p.start()
    p.join()
    # 通过管道的另一方获取数据
    print(parent_conn.recv())
    parent_conn.close()
```

示例2

```python
import multiprocessing

def create_items(pipe):
    """生成1～9数字"""
    output_pipe, _ = pipe
    for item in range(10):
        output_pipe.send(item)
    output_pipe.close()

def multiply_items(pipe_1, pipe_2):
    """对数字进行乘方"""
    close, input_pipe = pipe_1
    close.close()
    output_pipe, _ = pipe_2
    try:
        while True:
            item = input_pipe.recv()
            output_pipe.send(item * item)
    except EOFError:
        output_pipe.close()

if __name__ == "__main__":
    # 第一个管道
    # 返回一个双向管道所连接的一对连接对象
    pipe_1 = multiprocessing.Pipe(True)
    process_pipe_1 = multiprocessing.Process(target=create_items, args=(pipe_1,))
    process_pipe_1.start()
    # 第二个管道
    pipe_2 = multiprocessing.Pipe(True)
    process_pipe_2 = multiprocessing.Process(target=multiply_items, args=(pipe_1, pipe_2,))
    process_pipe_2.start()
    pipe_1[0].close()
    pipe_2[0].close()
    try:
        while True:
            print(pipe_2[1].recv())
    except EOFError:
        print('End')
```

## 进程同步

当多个进程需要访问共享资源时，为了避免冲突multiprocessing模块提供了多种机制实现进程间同步

### 共享内存

使用共享内存实现进程间数据传递，比较适合大量数据的场合

```python
from multiprocessing import Process, Value, Array

def f(n, a):
    n.value = 3.1415926
    for i in range(len(a)):
        a[i] = a[i]*a[i]

if __name__ == "__main__":
    # 实型
    num = Value('d', 0.0)
    # 整型数组
    arr = Array('i', range(10))
    # 创建进程对象
    p = Process(target=f, args=(num, arr))
    p.start()
    p.join()
    print(num.value)
    pritn(arr[:])
```

### Lock

锁机制通过对共享资源上锁的方式避免多个进程的访问冲突

```python
import multiprocessing
import sys

def process1(lock, f):
    with lock:
        fs = open(f, 'a+')
        times = 10
        while times > 0:
            fs.write('process1 write\n')
            times -= 1
        fs.close()
        
def process2(lock, f):
    # 上锁
    lock.acquire()
    try:
        fs = open(f, 'a+')
        times = 10
        while times > 0:
            fs.write('process2 write\n')
            tiems -= 1
        fs.close()
    finally:
        // 解锁
        lock.release()
        
        
if __name__ == '__main__':
    # 创建锁
    lock = multiprocessing.Lock()
    f = 'share.txt'
    p1 = multiprocessing.Process(target = process1, args=(lock, f))
    p2 = multiprocessing.Process(target = process2, args=(lock, f))
    p1.start()
    p2.start()
    p1.join()
    p2.join()
```

### RLock

RLock是Lock的递归版。`lock.aquire()`是请求锁，当前的锁为锁定状态时，`lock.acquire()`会阻塞等待锁释放。若写了两个`lock.aquire()`会产生死锁，则第二个`lock.aquire()`会永远等待在那里

使用RLock则不会出现这种情况，RLock支持在同一资源上多个锁，上多少把锁，就得释放多少次。

### Event

实现进程间的简单通信，一个进程会发出事件，其他进程会等待事件，Event对象有两种方法：`set()`与`clear()`，用于管理内部的标志

```python
from multiprocessing import Process, Event

def f(e, i):
    if e.is_set():
        e.wait()
        print('hello word', i)
        e.clear()
    else:
        e.set()
        
        
if __name__ == '__main__':
    e = Event()
    for num in range(10):
        Process(target=f, args=(e, num)).start()
```

### Semaphore

semaphore有信号量的意思，与Lock有些类似。Semaphore可以指定允许访问资源的进程数量。通俗来讲就是，该资源有多个门，每个门对应一把锁。一个进程访问了该资源，锁了门，还有其他门可以使用。如果所有的门都被锁了，那么新的进程就必须等待现有进程推出并释放锁后才可以访问

```python
import multiprocessing
import time

def process1():
	s.acquire()
	print('process1 acquire and it will sleep 5s')
    time.sleep(5)
    print('process1 release');
    s.release()
    
def process2():
    s.acquire()
    print('process2 acquire and it will sleep 5s')
    time.sleep(5)
    print('process2 release')
    s.release()
    
def process3():
    print('process3 try to start')
    s.acquire()
    print('process3 acquire and it will sleep 5s')
    time.sleep(5)
    print('process release')
    s.release()
    
if __name__ == '__main__':
    # 限制为最多两个进程同时访问
    s = multiprocessing.Semaphore(2)
    p1 = multiprocessing.Process(target = process1)
    p2 = multiprocessing.Process(target = process2)
    p3 = multiprocessing.Process(target = process3)
    # 依次启动3个进程，当前两个进程未推出时，进程3尝试访问失败，当进程1退出后，进程3才获得权限
    p1.start()
    time.sleep(1)
    p2.start()
    time.sleep(1)
    p3.start()
    time.sleep(1)
```

### Barrier

将一个程序划分为几个阶段，因为它要求所有进程都到达后才能开始执行。屏障后的代码不能与屏障前的代码并发执行

```python
import multiprocessing
from multiprocessing import Barrier, Lock, Process
from time import time
from datetime import datetime

def test_with_barrier(synchronizer, serializer):
    name = multiprocessing.current_process().name
    synchronizer.wait()
    now = time()
    with serializer:
        print("process %s ----> %s" %(name, datetime.fromtimestamp(now)))

def test_without_barrier():
    name = multiprocessing.current_process().name
    now = time()
    print("process %s ----> %s" %(name, datetime.fromtimestamp(now)))

if __name__ == "__main__":
    # create a barrier and lock. 
    synchronizer = Barrier(2)  # 2表示管理2个进程饿
    serializer = Lock()
    # create four processes
    Process(name='p1 - test_with_barrier', target=test_with_barrier, args=(synchronizer, serializer)).start()
    Process(name='p2 - test_with_barrier', target=test_with_barrier, args=(synchronizer, serializer)).start()
    Process(name='p3 - test_without_barrier', target=test_without_barrier).start()
    Process(name='p4 - test_without_barrier', target=test_without_barrier).start()
```

## Listener/Client

这两个对象是`multiprocessing.connection`模块提供的对象，可以在不同机器上的进程之间通过网络直接传输整数、实数、字符串、列表、元组、数组等各种类型的信息

使用Listener于Client对象在不同机器上传递消息，用来验证服务端是否存活

```python
# 服务端代码
from multiprocessing.connection import Listener
from time import sleep

with Listener(('', 6060), authkey=b'leili') as listener:
    with listener.accept() as conn:
        print('connection accepted from', listener.last_accepted)
        i = 0
        while True:
            conn.send(('server is alive', i))
            i += 1
            sleep(3)
            
# 客户端代码
from multiprocessing.connection import Client

with Client(('10.2.1.2', 6060), authkey=b'leili') as conn:
    while True:
        print(conn.recv())
```

## Subprocess

很多时候，子进程并不是自身，而是一个外部进程。我们创建了子进程后，还需要控制子进程的输入和输出。

`subprocess`模块可以让我们非常方便地启动一个子进程，连接子进程的输入输出管道，并获得子进程的返回码。

创建函数

```python
run()
# 会阻塞当前进程，子进程结束后返回码和其他信息的CompletedProcess对象
call()
# 会阻塞当前进程，子进程结束后直接得到返回码
Popen()
# 不阻塞当前进程，直接返回得到Popen对象，通过该对象可以对子进程进行更多的操作和控制
# Popen对象的kill()和terminate()方法可以用来结束该进程
# send_signal()可以给子进程发送指定信号
# wait()用来等待子进程运行结束
# pid用来显示子进程的ID号
```

demo

```
# 在Python代码中运行命令nslookup www.python.org,等同命令行直接运行
import subprocess

print('$ nslookup www.python.org')
r = subprocess.call(['nslookup', 'www.python.org'])
print('Exit code:', r)
```

如果子进程还需要输入，则可以通过`communicate()`方法输入：

```python
# 等同命令行输入set q=mx  python.org  exit
import subprocess

print('$ nslookup')
p = subprocess.Popen(['nslookup'], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
output, err = p.communicate(b'set q=mx\npython.org\nexit\n')
print(output.decode('utf-8'))
print('Exit code:', p.returncode)
```

## 分布式进程

```
在Thread和Process中，应当优选Process，因为Process更稳定，而且，Process可以分布到多台机器上，而Thread最多只能分布到同一台机器的多个CPU上。

Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。
```

如果我们已经有一个通过`Queue`通信的多进程程序在同一台机器上运行，现在，由于处理任务的进程任务繁重，希望把发送任务的进程和处理任务的进程分布到两台机器上。怎么用分布式进程实现？

原有的`Queue`可以继续使用，但是，通过`managers`模块把`Queue`通过网络暴露出去，就可以让其他机器的进程访问`Queue`了。

1. 我们先看服务进程，服务进程负责启动`Queue`，把`Queue`注册到网络上，然后往`Queue`里面写入任务：

```python
# task_master.py

import random, time, queue
from multiprocessing.managers import BaseManager

# 发送任务的队列:
task_queue = queue.Queue()
# 接收结果的队列:
result_queue = queue.Queue()

# 从BaseManager继承的QueueManager:
class QueueManager(BaseManager):
    pass

# 把两个Queue都注册到网络上, callable参数关联了Queue对象:
QueueManager.register('get_task_queue', callable=lambda: task_queue)
QueueManager.register('get_result_queue', callable=lambda: result_queue)
# 绑定端口5000, 设置验证码'abc':
manager = QueueManager(address=('', 5000), authkey=b'abc')
# 启动Queue:
manager.start()
# 获得通过网络访问的Queue对象:
task = manager.get_task_queue()
result = manager.get_result_queue()
# 放几个任务进去:
for i in range(10):
    n = random.randint(0, 10000)
    print('Put task %d...' % n)
    task.put(n)
# 从result队列读取结果:
print('Try get results...')
for i in range(10):
    r = result.get(timeout=10)
    print('Result: %s' % r)
# 关闭:
manager.shutdown()
print('master exit.')
```

请注意，当我们在一台机器上写多进程程序时，创建的`Queue`可以直接拿来用，但是，在分布式多进程环境下，添加任务到`Queue`不可以直接对原始的`task_queue`进行操作，那样就绕过了`QueueManager`的封装，必须通过`manager.get_task_queue()`获得的`Queue`接口添加。

然后，在另一台机器上启动任务进程（本机上启动也可以）：

```python
# task_worker.py

import time, sys, queue
from multiprocessing.managers import BaseManager

# 创建类似的QueueManager:
class QueueManager(BaseManager):
    pass

# 由于这个QueueManager只从网络上获取Queue，所以注册时只提供名字:
QueueManager.register('get_task_queue')
QueueManager.register('get_result_queue')

# 连接到服务器，也就是运行task_master.py的机器:
server_addr = '127.0.0.1'
print('Connect to server %s...' % server_addr)
# 端口和验证码注意保持与task_master.py设置的完全一致:
m = QueueManager(address=(server_addr, 5000), authkey=b'abc')
# 从网络连接:
m.connect()
# 获取Queue的对象:
task = m.get_task_queue()
result = m.get_result_queue()
# 从task队列取任务,并把结果写入result队列:
for i in range(10):
    try:
        n = task.get(timeout=1)
        print('run task %d * %d...' % (n, n))
        r = '%d * %d = %d' % (n, n, n*n)
        time.sleep(1)
        result.put(r)
    except Queue.Empty:
        print('task queue is empty.')
# 处理结束:
print('worker exit.')
```

任务进程要通过网络连接到服务进程，所以要指定服务进程的IP。

现在，可以试试分布式进程的工作效果了。先启动`task_master.py`服务进程：

```
python3 task_master.py
```

`task_master.py`进程发送完任务后，开始等待`result`队列的结果。现在启动`task_worker.py`进程：

```
python3 task_worker.py
```

`task_worker.py`进程结束，在`task_master.py`进程中会继续打印出结果

**注意：**

Queue对象存储在`task_master.py`进程中，而`Queue`之所以能通过网络访问，就是通过`QueueManager`实现的。由于`QueueManager`管理的不止一个`Queue`，所以，要给每个`Queue`的网络调用接口起个名字，比如`get_task_queue`。

`authkey`是为了保证两台机器正常通信，不被其他机器恶意干扰。如果`task_worker.py`的`authkey`和`task_master.py`的`authkey`不一致，肯定连接不上

Queue的作用是用来传递任务和接收结果，每个任务的描述数据量要尽量小。比如发送一个处理日志文件的任务，就不要发送几百兆的日志文件本身，而是发送日志文件存放的完整路径，由Worker进程再去共享的磁盘上读取文件

## 多进程版文件复制器

```
import multiprocessing
import os
import time
import random


def copy_file(queue, file_name,source_folder_name,  dest_folder_name):
    """copy文件到指定的路径"""
    f_read = open(source_folder_name + "/" + file_name, "rb")
    f_write = open(dest_folder_name + "/" + file_name, "wb")
    while True:
        time.sleep(random.random())
        content = f_read.read(1024)
        if content:
            f_write.write(content)
        else:
            break
    f_read.close()
    f_write.close()

    # 发送已经拷贝完毕的文件名字
    queue.put(file_name)


def main():
    # 获取要复制的文件夹
    source_folder_name = input("请输入要复制文件夹名字:")

    # 整理目标文件夹
    dest_folder_name = source_folder_name + "[副本]"

    # 创建目标文件夹
    try:
        os.mkdir(dest_folder_name)
    except:
        pass  # 如果文件夹已经存在，那么创建会失败

    # 获取这个文件夹中所有的普通文件名
    file_names = os.listdir(source_folder_name)

    # 创建Queue
    queue = multiprocessing.Manager().Queue()

    # 创建进程池
    pool = multiprocessing.Pool(3)

    for file_name in file_names:
        # 向进程池中添加任务
        pool.apply_async(copy_file, args=(queue, file_name, source_folder_name, dest_folder_name))

    # 主进程显示进度
    pool.close()

    all_file_num = len(file_names)
    while True:
        file_name = queue.get()
        if file_name in file_names:
            file_names.remove(file_name)

        copy_rate = (all_file_num-len(file_names))*100/all_file_num
        print("\r%.2f...(%s)" % (copy_rate, file_name) + " "*50, end="")
        if copy_rate >= 100:
            break
    print()


if __name__ == "__main__":
    main()
```

#mpi4py

## 概览

示例

```python
# hello.py
from mpi4py import MPI

comm = MPI.COMM_WORLD  # 通信器，定义了自己的一套可互相通信的进程
rank = comm.Get_rank() # 返回调用它的那个进程的等级
print("hello world from process ", rank)
```

执行

```
mpiexec -n 5 python hello.py
```

说明

```
在MPI中，并行程序执行过程中所涉及的进程可以由一个非负的整数序列进行标识，这些证书叫做等级(rank)。若一个程序有p个进程在运行，那么进程的等级就会从0到p-1.

标准输出上的输出并非总是有序的，因为多个进程会同时向屏幕写内容，操作系统则会随意选择顺序。因此，得到一个基本的结论：MPI执行过程中所涉及的每个进程都会运行相同的编译好的二进制代码，这样每个进程都会收到同样的待执行指令
```

## 点对点通信

点对点通信指的是可以在两个进程间传递数据：一个进程接收者，一个进程发送者

python模块的mpi4py通过以下函数实现

```python
comm.send(data, process_destination)
# 将数据发送给目标进程，目标进程是由其在通信器组中的等级来标识的
comm.recv(process_source)
# 从源进程接收数据，源进程也是由其在通信器组中的等级来标识的
comm = MPI.COMM_WORLD
# 通信器，定义了进程组，可以通过消息传递来通信
```

注意

```
comm.send()与comm.recv()函数都是阻塞函数，它们会阻塞调用者，直到缓冲数据被安全地址使用为止。在MPI中，有两种发送与接收消息的方法：缓冲模式、同步模式。
在缓冲模式中，当待发送的数据被复制到缓冲区后，流程控制就会返回到程序中。这并不意味着消息已经被发送或是接收了。
在同步模式中，只有在响应的接收函数开始接收消息时，函数才会终止。
```

- 在不同进程间交换信息

```python
from mpi4py import MPI

# 通信组comm
comm = MPI.COMM_WORLD
# 标识出组中的任务与进程
rank = comm.rank
print('my rank is: ', rank)

# rank值为0的进程会向rank值为4的接收者进程发送一个数字数据
if rank==0:
    data = 10000000
    destination_process = 4
    comm.send(data, dest=destination_process)
    print("sending data %s" % data + "to process %d" % destination_process)
    
if rank==1:
    data = "hello"
    destination_process = 8
    comm.send(data, dest=destination_process)
    print("sending data %s" % data + "to process %d" % destination_process)

# rank值为4的接收者进程
if rank==4:
    # recv必须包含一个从那还素，该参数指定了发送者进程的rank值
    data = comm.recv(source=0)
    print("data received is = %s" % data)

if rank==8:
    data1 = comm.recv(source=1)
    pritn("data received is = %s" data1)
```

## 避免死锁

死锁是两个或多个进程彼此阻塞，一个进程等待另一个进程执行某个动作来满足自己的需要，反之亦然。mpi4py模块并未提供任何具体的功能来解决这一问题，它只是提供了一些举措，开发者需要遵循这些举措来避免死锁问题

示例

```python
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.rank
print('my rank is: ', rank)

if rank == 1:
    data_send = "a"
    destination_process = 5
    source_process = 5
    data_received = comm.recv(source=source_process)
    comm.send(data_send, dest=destination_process)
    print("sending data %s" % data_send + "to process %d" % destination_process)
    print("data received is = %s" % data_received)

if rank == 5:
    data_send = "b"
    destination_process = 1
    source_process = 1
    data_received = comm.recv(source=source_process)
    comm.send(data_send, dest=destination_process)
    print("sending data %s" % data_send + "to process %d" % destination_process)
    print("data received is = %s" % data_received)
```

运行

```shell
mpiexec -n 9 python deadLockProblems.py
```

两个进程都想从过年对方那里接收消息，但都卡住了。首先想到的解决方案

```python
if rank == 1:
    data_send = "a"
    destination_process = 5
    source_process = 5
    comm.send(data_send, dest=destination_process)
    data_received = comm.recv(source=source_process)

if rank == 5:
    data_send = "b"
    destination_process = 1
    source_process = 1
    data_received = comm.recv(source=source_process)
    comm.send(data_send, dest=destination_process)
```

不过，这个解决方案虽然从逻辑上ok，但无法总能避免死锁问题。由于通信是经由缓冲区进行的，而缓冲区是comm.send()MPI复制待发送数据的地方，因此程序能够平滑运行的前提是该缓冲区可以承载所有数据，否则就会导致死锁；发送者无法发送完整数据，因为缓冲区已满，而接收者无法接收数据，因为它被comm.send()MPI阻塞了，无法完成。这时，避免死锁的一种解决方案就是交换发送与接收函数的位置，使它们变成非对称的

```python
if rank == 1:
    data_send = "a"
    destination_process = 5
    source_process = 5
    comm.send(data_send, dest=destination_process)
    data_received = comm.recv(source=source_process)

if rank == 5:
    data_send = "b"
    destination_process = 1
    source_process = 1
    comm.send(data_send, dest=destination_process)
    data_received = comm.recv(source=source_process)
```

上面并非唯一解决方案。比如，有这样一个特殊函数，它统一了向给定进程发送消息的调用与接收来自另外一个线程的消息的调用，该函数叫做Sendrecv

```python
Sendrecv(self, sendbuf, int dest=0, int sendtag=0, recvbuf=None, int source=0, int recvtag=0, Status status=None)
```

如此，所需参数与comm.send()MPI和comm.recv()MPI相同。此外，在该示例中，函数会阻塞，不过相比于之前看到的两个函数来说，它的优势在于让通信子系统负责检查发送与接收的依赖关系，从而避免了死锁。

```python
if rank == 1:
    data_send = "a"
    destination_process = 5
    source_process = 5
    comm.send(data_send, dest=destination_process)
    data_received = comm.recv(source=source_process)

if rank == 5:
    data_send = "b"
    destination_process = 1
    source_process = 1
    comm.send(data_send, dest=destination_process)
    data_received = comm.recv(source=source_process)
```

## 聚合通信

借助于聚合通信，可以实现一个组内的多个进程间同时进行数据传递。mpi4py只提供了聚合通信的阻塞版本(会阻塞调用者方法，直至缓冲区数据可以安全使用为止)

常见的聚合操作有

```
- 跨越组内进程的屏障同步
- 通信功能
	- 从一个进程向组内其他所有进程广播数据
	- 将所有进程的数据收集到一个进程
	- 从一个进程将数据分发到其他进程
- 汇聚操作
```

### 广播

在并行代码的时候，常遇到如下情况：运行期需要在多个进程间共享某个变量的值，或是共享由每个进程所提供的对变量的操作(操作不同的值)

为了解决这个问题，我们使用通信树(如，进程0向进程1与2发送数据，进程1与2则分别将数据发送给进程3,4,5等)

涉及属于某个通信器的所有进程的通信方法叫做聚合通信。因此，聚合通信一般来说会涉及两个以上的进程。不过，我们会将聚合通信叫做广播，其中一个进程向其他进程发送相同的数据。广播中的mpi4py功能由如下函数提供，该函数只是将消息进程根中的信息发送给属于comm通信器的其他进程；不过，每个进程都必须要通过相同的root与comm值来调用它。

```python
buf = comm.bcast(data_to_share, rank_of_root_process)

# 参数
data_to_share			待共享的数据
rank_of_root_process	根进程或主发送进程
```

示例

```python
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

if rank == 0:
    variable_to_share = 100
else:
    variable_to_share = None

variable_to_share = comm.bcast(variable_to_share, root=0)
print("process = %d" % rank + "variable shared = %d" % variable_to_share)
```

运行

```
mpiexec -n 10 python broadcast.py  # 开启10个进程
```

### scatter

scatter的功能类似于scatter广播，但是虽然comm.bcast会向所有舰艇进程发送同样的数据，但comm.scatter却能以数组形式将数据块发送给不同进程。

`comm.scatter`函数会接收数组元素，并根据进程的等级值将它们发送给相应的进程。地1个元素会被发送给进程0，第2个元素会被发送给进程1，以此类推。

mpi4py函数实现

```python
recvbuf = comm.scatter(sendbuf, rank_of_root_process)
```

还提供了另外两个函数用于散播数据

```python
comm.scatter(sendbuf, recvbuf, root=0)
# 会将相同通信器中的一个进程的数据发送给所有其他进程
comm.scatterv(sendbuf, recvbuf, root=0)
# 会将一个组中一个进程的数据发送给所有其他进程。在发送端，可以发送不同数量的数据，偏移量也可以不同

sendbuf与recvbuf参数必须以列表的形式给出:buf = [data, data_size, data_type]
data必须是一个类似于缓冲的对象，其大小为data_size，类型为data_type
```

示例

```python
from mpi4py import MPI

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

if rank == 0:
    array_to_share = [1,2,3,4,5,6,7,8,9,10]
else:
    variable_to_share = None

# 通过comm.scatter将要发送给第i个进程的第i个变量的值
recvbuf = comm.scatter(array_to_share, root=0)
print("process = %d" % rank + "recvbuf= %d" % array_to_share)
```

运行

```
mpiexec -n 10 python scatter.py
```

### gather

gather函数会执行与scatter相反的功能。在该示例中，所有进程会向根进程发送数据，根进程则会收集所接收到的数据。

mpi4py实现

```
recvbuf = comm.gather(sendbuf, rank_of_root_process)

# 参数
sendbuf					发送的数据
rank_of_root_process	所有数据的进程接收者
```

收集数据函数

```python
# 收集到一个任务
comm.Gather/comm.Gatherv/comm.gather

# 收集到所有任务
comm.Allgather/comm.Allgatherv/comm.allgather
```

示例

```python
from mpi4py import MPI

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()
data = (rank + 1) ** 2  # 有n个进程来发送数据
data = comm.gather(data, root=0) # 实现收集数据

if rank == 0:  # 如果进程的rank值为0，那么数据就会被收集到数组中
    print("rank = %s " % rank + "...receiving data to other process")
    for i in range(1, size):
        data[i] = (i + 1) ** 2
        value = data[i]
        print("process = %s receiving %s from process %s" % (rank, value, i))
```

运行

```
mpiexec -n 5 python gather.py
```

### Alltotall

Alltoall聚合通信整合了scatter与gather的功能。mpi4py中有3类Alltoall聚合通信

```python
comm.Alltoall(sendbuf, recvbuf)
# all-to-all scatter/gather从组中的all-to-all进程发送数据
comm.Alltoallv(sendbuf, recvbuf)
# all-to-all scatter/gather从组中的all-to-all进程发送数据，提供了不同的数据量与偏移量
comm.Alltoallw(sendbuf, recvbuf)
# 广义的all-to-all通信，支持每个进程使用不同数量、不同偏移量与不同数据类型的数据
```

All-to-all个性化通信又叫做全交换。该操作可用在各种并行算法中，如傅里叶变换、矩阵转置、抽样排序以及一些并行的数据库操作连接操作等。

示例

```python
from mpi4py import MPI
import numpy

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()

a_size = 1
senddata = (rank + 1) * numpy.arrange(size, dtype=int)
recvdata = numpy.empty(size*a_size, dtype=int)
comm.Alltoall(senddata, recvdata)  # 从任务j的sendbuf中接收到第i个对象，然后将其肤质懂啊任务i的recvbuf的第j个对象处

print("process %s sending %s receiving %s" % (rank, senddata, recvdata))
```

运行

```
mpiexec -n 5 python alltoall.py
```

注意

```
[
	0 1 2 3 4
	0 2 4 6 8
	0 3 6 9 12
	0 4 8 12 16
	0 5 10 15 20
]
经过Alltoall
[
    0 0 0 0 0 
    1 2 3 4 5
    2 4 6 8 10
    3 6 9 12 15
    4 8 12 16 20
]
```

### 汇聚操作

类似于`comm.gather`,`comm.reduce`也会在每个进程中接收一个输入元素的数组，并将一个输出元素的数组返回给根进程。输出元素包含了汇聚后的结果

mpi4py中实现

```python
comm.Reduce(sendbuf, recvbuf, rank_of_root_process, op=type_of_reduction_operation)
```

`comm.gather`语句位于op参数中了，它指的是希望对数据所应用的操作，mpi4py模块包含了一组可以使用的汇聚操作。由MPI所定义的一些汇聚操作有如下几项

```
MPI.MAX		返回最大的元素
MPI.MIN		返回最小的元素
MPI.SUM		对元素求和
MPI.PROD	对所有元素相乘
MPI.LAND	对元素执行一个逻辑运算
MPI.MAXLOC	返回最大值以及拥有该最大值的进程的rank值
MPI.MINLOC	返回最小值以及拥有该最小值的进程的rank值
```

示例

```python
from mpi4py import MPI
import numpy


comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()

array_size = 3
recvdata = numpy.zeros(array_size, dtype=numpy.int)
senddata = (rank + 1) * numpy.arrange(array_size, dtype=numpy.int)
print("process %s sending %s " % (rank, senddata))
comm.Reduce(senddata, recvdata, root=0, op=MPI.SUM)  # 执行汇聚求和
print('on task', rank, 'after Reduce: data =  ', recvdata)
```

运行

```
mpiexec -n 3 python reduction2.py
```

## 如何优化通信

MPI所提供的一个有趣的特性是关于虚拟拓扑的。如前所属，所有的通信功能都指的是一组进程。我们总是在使用MPI_COMM_WORLD组，它包含了所有进程。它会为属于大小为n的通信器的每一个进程分配一个从0到n-1的rank值。不过，我们可以通过MPI为通信器分配一个虚拟拓扑。它为不同的进程定义了特殊的标签。这种机制可以提升执行性能。实际上，如果构建了虚拟拓扑，那么每个节点都只会于其虚拟邻居通信，这优化了性能

比如，如果rank值是随机分配的，那么消息在到达目的地前就会经过很多其他节点。除了性能问题以外，虚拟拓扑还可以确保代码更清晰，可读性更好。MPI提供了来个闹钟功能构建拓扑。第一种会创建笛卡儿拓扑，第二种会创建其他类型的拓扑。特别的，对于第二种情况，必须要为想要构建的图提供邻接矩阵。这里只讨论笛卡儿拓扑，通过它可以构建出几种广泛使用的结构：如网状、环形与螺旋状等。

创建笛卡儿拓扑的函数

```python
comm.Create_cart(number_of_rows, number_of_columns)

# 参数
number_of_rows		将要创建的网格的行数
number_of_columns	将要创建的网格的列数
```

示例

```python
from mpi4py import MPI
import numpy as np


UP = 0
DOWN = 1
LEFT = 2
RIGHT = 3
neighbour_processes = [0, 0, 0, 0]

if __name__ == "__main__":
    comm = MPI.COMM_WORLD
    size = comm.size
    rank = comm.rank

    # 生成的拓扑是一个2*2的网状结构，其大小等于输入的进程数
    grid_rows = int(np.floor(np.sqrt(comm.size)))
    grid_column = comm.size // grid_rows

    if grid_rows*grid_column > size:
        grid_column -= 1
    if grid_rows*grid_column > size:
        grid_rows -= 1

    if rank == 0:
        print("Building a %d x %d grid topology:" % (grid_rows, grid_column))

    # 构建笛卡儿拓扑
    cartesian_communicator = comm.Create_cart((grid_rows, grid_column), periods=(True, True), reorder=True)  # periods的值False，True待定
    # 为了找出第i个进程的位置，使用Get_coords()
    my_mpi_row, my_mpi_col = cartesian_communicator.Get_coords(cartesian_communicator.rank)
    # 获取拓扑
    neighbour_processes[UP], neighbour_processes[DOWN] = cartesian_communicator.Shift(0, 1)
    neighbour_processes[LEFT], neighbour_processes[RIGHT] = cartesian_communicator.Shift(1, 1)

    print("Process = %s row = %s column = %s ---> \
         neighbour_process[UP] = %s neighbour_process[DOWN] = %s\
         neighbour_process[LEFT] = %s neighbour_process[RIGHT] = %s"\
         (rank, my_mpi_row, my_mpi_col, \
          neighbour_processes[UP], neighbour_process[DOWN], neighbour_process[LEFT], neighbour_process[RIGHT]))
```

运行

```
mpiexec -n 4 python virtualTopology.py
```


# 随机森林

随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。

优缺点

```
# 优点
1.能够解决单个决策树不稳定的情况
2.能够处理具有高维特征的输入样本，而且不需要降维（使用的是特征子集）
3.对于缺省值问题也能够获得很好得结果（投票）

# 缺点
随机森林已经被证明在某些噪音较大的分类或回归问题上会过拟合
```

## 原理

Bagging + Base Estimator: Decision Tree

决策树在节点划分上，在随机的特征子集上寻找最优划分特征

- Extra-Tree

决策树在节点划分上，使用随机的特征和随机的阈值

提供了额外的随机性，抑制过拟合，但增大了bias

更快的训练速度

- 优点

```
1. 能够处理很高维度(feature很多)的数据，并且不用做特征选择
2. 在训练完成后，能够给出哪些feature比较重要
3. 容易做成并行化方法，速度比较快
4. 可以进行可视化， 便于分析
```

注意：理论上越多的树效果越好，但实际上基本超过一定数量就上下浮动了

## sklearn

### API

```python
# 随机森林分类器
class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=’gini’, max_depth=None,bootstrap=True, random_state=None)

# 输入
n_estimators：integer，optional（default = 10） 森林里的树木数量
criteria：string，可选（default =“gini”）分割特征的测量方法
max_depth：integer或None，可选（默认=无）树的最大深度 
bootstrap：boolean，optional（default = True）是否在构建树时使用放回抽样 
```

### 随机森林

```python
import numpy as np
import matplotlib.pylot as plt
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier

X, y = datasets.make_noons(n_samples=500, noise=0.3, random_state=666)

plt.scatter(X[y==0, 0], X[y==0, 1])
plt.scatter(X[y==1, 0], X[y==1, 1])
plt.show()

rf_clf = RandomForestClassifier(
		n_estimators=500,
  	random_state=666,
  	oob_score=True,
  	n_jobs=-1
)
rf_clf.fit(X, y)
print(rf_clf.oob_score_)

# 修改参数
rf_clf2 = RandomForestClassifier(
		n_estimators=500,
  	max_leaf_nodes=16,
  	random_state=666,
  	oob_score=True,
  	n_jobs=-1
)
rf_clf2.fit(X, y)
print(rf_clf2.oob_score_)
```

### Extra-Tree

```python
from sklearn.ensemble import ExtraTreesClassifier

et_clf = ExtraTreesClassifier(
		n_estimators=500,
  	bootstrap=True,
  	oob_score=True,
  	random_state=666
)
et_clf.fit(X, y)
print(et_clf.oob_score_)
```

### 解决回归问题

```python
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import ExtraTreeRegressor
```

### 示例

```python
# 1.导入合适的包
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier,export_graphviz
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier

# 2.加载数据
data = pd.read_csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt")
# 3.数据处理
# 填补缺失值age
data["age"].fillna(data["age"].mean(), inplace=True)
# 雷彪数据进行One-Hot编码
data = pd.get_dummies(data, columns=["pclass", "sex"]) 
print(data.head(2))
# 4.特征选择和数据集分割
# 特征值
x = data[["age", "pclass_1st", "pclass_2nd", "pclass_3rd", "sex_female", "sex_male"]]
# 目标值
y = data["survived"]
# 数据集分割
x_train, x_test, y_train, y_test = train_test_split(x, y)
# 5.随机森林估计器流程
rfc = RandomForestClassifier(n_estimators=5, criterion="entropy", max_depth=4)
rfc.fit(x_train, y_train)
# 5.预测
predict = rfc.predict(x_test)
# 6.准确率
score = rfc.score(x_test, y_test)
print(score)
```


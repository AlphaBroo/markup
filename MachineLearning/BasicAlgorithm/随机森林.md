# 随机森林

## 原理

Bagging + Base Estimator: Decision Tree

决策树在节点划分上，在随机的特征子集上寻找最优划分特征

- Extra-Tree

决策树在节点划分上，使用随机的特征和随机的阈值

提供了额外的随机性，抑制过拟合，但增大了bias

更快的训练速度

## sklearn

### 随机森林

```python
import numpy as np
import matplotlib.pylot as plt
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier

X, y = datasets.make_noons(n_samples=500, noise=0.3, random_state=666)

plt.scatter(X[y==0, 0], X[y==0, 1])
plt.scatter(X[y==1, 0], X[y==1, 1])
plt.show()

rf_clf = RandomForestClassifier(
		n_estimators=500,
  	random_state=666,
  	oob_score=True,
  	n_jobs=-1
)
rf_clf.fit(X, y)
print(rf_clf.oob_score_)

# 修改参数
rf_clf2 = RandomForestClassifier(
		n_estimators=500,
  	max_leaf_nodes=16,
  	random_state=666,
  	oob_score=True,
  	n_jobs=-1
)
rf_clf2.fit(X, y)
print(rf_clf2.oob_score_)
```

### Extra-Tree

```python
from sklearn.ensemble import ExtraTreesClassifier

et_clf = ExtraTreesClassifier(
		n_estimators=500,
  	bootstrap=True,
  	oob_score=True,
  	random_state=666
)
et_clf.fit(X, y)
print(et_clf.oob_score_)
```

### 解决回归问题

```python
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import ExtraTreeRegressor
```


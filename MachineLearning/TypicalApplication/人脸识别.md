# 人脸识别

## SVM

```python
import numpy as np
import pandas as pd
import matplotlib as mpl
import seaborn as sns
import time
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_lfw_people
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

faces = fetch_lfw_people(min_faces_per_person=60)
print(faces.target_names)
# ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'
#  'Gerhard Schroeder' 'Hugo Chavez' 'Junichiro Koizumi' 'Tony Blair']
print(faces.images.shape)
# (1348, 62, 47)

# 画一些人脸，查看需要处理的数据
# fig, ax = plt.subplots(3, 5)
# for i, axi in enumerate(ax.flat):
#     axi.imshow(faces.images[i], cmap='bone')
#     axi.set(xticks=[], yticks=[], xlabel=faces.target_names[faces.target[i]])
# plt.show()

# 主成分分析提取150个基本元素，而不是使用每个像素作为特征
pca = PCA(n_components=150, whiten=True, random_state=42)
svc = SVC(kernel='rbf', class_weight='balanced')
model = make_pipeline(pca, svc)

# 数据集分离
Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)
# 网格搜索寻找超参数最优值
param_grid = {
    "svc__C": [ 1, 5, 10, 50],
    "svc__gamma": [0.0001, 0.0005, 0.001, 0.005]
}
grid = GridSearchCV(model, param_grid)

now = time.process_time()
grid.fit(Xtrain, ytrain)
print(time.process_time() - now)  # 138.956965
print(grid.best_params_)  # {'svc__C': 10, 'svc__gamma': 0.001}
# 最优参数是在网格的中间位置，若是在边缘位置，需要扩展网格搜索范围

# 对测试集进行预测
model = grid.best_estimator_
yfit = model.predict(Xtest)

# 对比测试结果
# fig, ax = plt.subplots(4, 6)
# for i, axi in enumerate(ax.flat):
#     axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')
#     axi.set(xticks=[], yticks=[])
#     axi.set_ylabel(faces.target_names[yfit[i]].split()[-1], color='black' if yfit[i] == ytest[i] else 'red')
# fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14)
# plt.show()

# 分类效果报告
res = classification_report(ytest, yfit, target_names=faces.target_names)
print(res)
"""
                   precision    recall  f1-score   support

     Ariel Sharon       0.65      0.73      0.69        15
     Colin Powell       0.80      0.87      0.83        68
  Donald Rumsfeld       0.74      0.84      0.79        31
    George W Bush       0.92      0.83      0.88       126
Gerhard Schroeder       0.86      0.83      0.84        23
      Hugo Chavez       0.93      0.70      0.80        20
Junichiro Koizumi       0.92      1.00      0.96        12
       Tony Blair       0.85      0.95      0.90        42

         accuracy                           0.85       337
        macro avg       0.83      0.84      0.84       337
     weighted avg       0.86      0.85      0.85       337
"""
# 混淆矩阵展示结果
mat = confusion_matrix(ytest, yfit)
sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
            xticklabels=faces.target_names, yticklabels=faces.target_names)
plt.xlabel('true label')
plt.ylabel('predicted label')
plt.show()
```

## Isomap

```python
import numpy as np
from matplotlib import offsetbox
import matplotlib.pyplot as plt
from matplotlib.image import imread
import seaborn as sns
from sklearn.datasets import fetch_lfw_people
from sklearn.decomposition import PCA
from sklearn.manifold import MDS, LocallyLinearEmbedding, Isomap, TSNE

faces = fetch_lfw_people(min_faces_per_person=30)
# print(faces.data.shape, faces.images.shape)
"""
(2370, 2914) (2370, 62, 47)
"""


# 有2370幅图像，每个图像有2914=62*47像素

# 快速可视化
# fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))
# for i, axi in enumerate(ax.flat):
#     axi.imshow(faces.images[i], cmap='gray')
# plt.show()

# PCA
# 判断主成分个数
# model = PCA(n_components=100, svd_solver='randomized').fit(faces.data)
# plt.plot(np.cumsum(model.explained_variance_ratio_))
# plt.xlabel(' n components')
# plt.ylabel('cumulative variable')
# plt.show()
# 通过累积方差图，知需要约100个成分才能保存90%的方差，说明数据所需的维度非常高，仅通过几个线性成分无法描述

# 采用非线性流形嵌入法Isomap
# model = Isomap(n_components=2)
# proj = model.fit_transform(faces.data)  # 输出对所有图像的一个二维投影
# print(proj.shape)  # (2370, 2)


# 在不同的投影位置输出图像的缩略图
def plot_components(data, model, images=None, ax=None, thumb_frac=0.05, cmap='gray'):
    ax = ax or plt.gca()
    proj = model.fit_transform(data)
    ax.plot(proj[:, 0], proj[:, 1], '.k')

    if images is not None:
        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2
        shown_images = np.array([2 * proj.max(0)])
        for i in range(data.shape[0]):
            dist = np.sum((proj[i] - shown_images) ** 2, 1)
            if np.min(dist) < min_dist_2:
                # 不展示相距很近的点
                continue
            shown_images = np.vstack([shown_images, proj[i]])
            imagebox = offsetbox.AnnotationBbox(offsetbox.OffsetImage(images[i], cmap=cmap), proj[i])
            ax.add_artist(imagebox)


fig, ax = plt.subplots(figsize=(10, 10))
plot_components(faces.data, model=Isomap(n_components=2), images=faces.images[:, ::2, ::2])
plt.show()
# 描述了图像的整体特征：图像明暗度从左至右持续斌华，人脸朝向从下到上持续变化。
# 可以根据这个结果将数据进行分类，用流形特征作为分类算法的输入数据
```


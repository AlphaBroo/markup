# 大数定律与中心极限定理

## 大数定律

- 切比雪夫不等式

设随机变量 $X$ 具有数学期望 $E(X)=\mu$，方差 $D(X)=\sigma^2$，则对于任意正数 $\varepsilon$，不等式
$$
P\{|X-\mu|\geq{\varepsilon}\}\leq{\frac{\sigma^2}{\varepsilon^2}}
$$
成立。这一不等式称为**切比雪夫不等式**

切比雪夫不等式等价于
$$
P\{|X-\mu|<{\varepsilon\sigma}\}>1-{\frac{1}{\varepsilon^2}}
$$
可知：

所有数据中，至少有3/4的数据位于平均数2个标准差范围内

所有数据中，至少有8/9的数据位于平均数3个标准差范围内

所有数据中，至少有15/16的数据位于平均数4个标准差范围内

- 弱大数定理(辛钦大数定理)

设 $X_1,X_2,...$ 是相互独立，服从同一分布的随机变量序列，且具有数学期望 $E(X_k)=\mu(k=1,2,...)$。作前$n$个变量的算术平均 $\frac{1}{n}\sum_{k=1}^{n}{X_k}$，则对于任意 $\epsilon>0$，有
$$
\lim_{n\rightarrow \infty}P\{|\frac{1}{n}{\sum_{k=1}^{n}{X_k}-\mu}|<\epsilon\}=1
$$

通俗地说，辛钦大数定理表明，对于独立同分布且具有均值 $\mu$ 的随机变量 $X_1,...,Xn$，当 $n$ 很大时它们的算术平均 $\frac{1}{n}{\sum_{k=1}^{n}{X_k}}$ 很可能接近于 $\mu$。

设 $Y_1,Y_2,...,Y_n,...$ 是一个随机变量序列，$a$ 是一个常数。若对于任意正数 $\epsilon$ ，有
$$
\lim_{n\rightarrow\infty}{P\{|Y_n-a|<\epsilon\}} = 1
$$
则称序列 $Y_1,Y_2,...Yn,...$ **依概率收敛于 $a$**。记为
$$
Y_n\stackrel{P}{\longrightarrow}a
$$
依概率收敛的序列有以下性质：

设 $X_n\stackrel{P}{\longrightarrow}a,Y_n\stackrel{P}{\longrightarrow}b$，又设函数 $g(x,y)$ 在点 $(a,b)$连续，则
$$
g(X_n,Y_n)\stackrel{P}{\longrightarrow}g(a,b)
$$
则辛钦大数定理又可序数为：

设随机变量 $X_1,X_2,...,X_n,...$ 相互独立，服从同一分布且具有数学期望 $E(X_k)=\mu(k=1,2,...)$ ，则序列 $\bar{X}=\frac{1}{n}{\sum_{k=1}^{n}{X_k}}$ 依概率收敛于 $\mu$，即 $\bar{X}\stackrel{P}{\longrightarrow}\mu$.

- 伯努利大数定理

设 $f_A$ 是 $n$ 次独立重复试验中事件A发生的次数，$p$ 是事件A在每次试验中发生的概率，则对于任意正数 $\epsilon>0$，有
$$
\lim_{n\rightarrow\infty}{P\{|\frac{f_A}{n}-p|<\epsilon\}} = 1
$$
或
$$
\lim_{n\rightarrow\infty}{P\{|\frac{f_A}{n}-p|\geq{\epsilon}\}} = 0
$$
伯努利大数定理的结果表明，对于任意 $\epsilon > 0$，只要重复独立试验 的次数 $n$ 充分打，事件 $\{|\frac{f_A}{n}-p|\geq{\epsilon}\}$ 是一个小概率事件，由实际推断原理知，这一事件几乎是不发生的，即在 $n$ 充分大时事件 $\{|\frac{f_A}{n}-p|<{\epsilon}\}$ 实际上几乎是必定要发生的，亦即对于给定的任意小的正数 $\epsilon$，在 $n$ 充分大时，事件“频率 $\frac{f_A}{n}$ 与概率 $p$ 的偏差小于 $\epsilon$” 实际上几乎必定要发生。这就是我们所说的频率稳定性的真正含义。由事件推断原理，在实际应用中，当试验次数很大时，便可以用事件的频率来代替事件的概率。

## 中心极限定理

在客观实际中有许多随机变量，它们是由大量的相互独立的随机因素的综合影响所形成 。而其中每一个别因素在总的影响中所起的作用都是微小的。这种随机变量往往近似地服从正态分布。

- 定理一：独立同分布的中心极限定理

设随机变量 $X_1,X_2,...,X_n,...$ 相互独立，服从同一分布，且具有数学期望和方差：$E(X_k)=\mu, D(X_k)=\sigma^2>0(k=1,2,...)$，则随机变量之和 $\sum_{k=1}^{n}{X_k}$ 的标准化变量
$$
Y_n= \frac{\sum_{k=1}^{n}{X_k}-E(\sum_{k=1}^{n}{X_k})}{\sqrt{D(\sum_{k=1}^{n}{X_k})}} = \frac{\sum_{k=1}^{n}X_k-n\mu}{\sqrt{n}\sigma}
$$
的分布函数 $F_n(x)$ 对于任意 $x$ 满足
$$
\begin{align*}
\lim_{n\rightarrow\infty}{F_n(x)}
&=\lim_{n\rightarrow\infty}{P\{\frac{\sum_{k=1}^{n}{X_k-n
\mu}}{\sqrt{n}\sigma}\leq{x}\}}\\
&=\int_{-\infty}^{x}{\frac{1}{\sqrt{2\pi}}e^{-t^2/2}\mathrm{d}t} \\
&=\Phi(x)
\end{align*}
$$
这就是说，均值为 $\mu$，方差为 $\sigma^2>0$ 的独立同分布的随机变量 $X_1,X_2,...,X_n$ 之和 $\sum_{k=1}^{n}{X_k}$ 的标准化变量，当 $n$ 充分大时，有
$$
\frac{\sum_{k=1}^{n}X_k-n\mu}{\sqrt{n}{\sigma}}\stackrel{近似地}{\sim}N(0,1)
$$
在一般情况下，很难求出 $n$ 个随机变量之和 $\sum_{k=1}^{n}{X_k}$ 的分布函数，当 $n$ 充分大时，可以通过 $\Phi(x)$ 给出其近似的分布。这样就可以利用正态分布对其进行理论分析或作实际计算。

对上式左侧改写 $\frac{\frac{1}{n}\sum_{k=1}^{n}X_k-\mu}{\sigma/\sqrt{n}}=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}$，这样，上式可写成，当 $n$ 充分大时，
$$
\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\stackrel{近似地}{\sim}N(0,1) 或 \bar{X}\stackrel{近似地}{\sim}N(\mu,\sigma^2/n)
$$

- 定理二：李雅普诺夫定理

设随机变量 $X_1,X_2,...,X_n,...$ 相互独立，它们具有数学期望和方差
$$
E(X_k)=\mu_{k}, D(X_k)=\sigma_k^2>0,k=1,2,...
$$
记
$$
B_n^2 = \sum_{k=1}^{n}{\sigma_k^2}
$$
若存在正数 $\delta$，使得当 $n\rightarrow\infty$时，
$$
\frac{1}{B_n^{2+\delta}}\sum_{k=1}^{n}{E\{|X_k-\mu_k|^{2+\delta}\}}\rightarrow 0
$$
则随机变量值和 $\sum_{k=1}^{n}{X_k}$ 的标准化变量
$$
Z_n= \frac{\sum_{k=1}^{n}{X_k}-E(\sum_{k=1}^{n}{X_k})}{\sqrt{D(\sum_{k=1}^{n}{X_k})}} = \frac{\sum_{k=1}^{n}X_k-\sum_{k=1}^{n}{\mu_k}}{B_n}
$$
的分布函数 $F_n(x)$ 对于任意 $x$，满足
$$
\begin{align*}
\lim_{n\rightarrow\infty}{F_n(x)}
&=\lim_{n\rightarrow\infty}{P\{\frac{\sum_{k=1}^{n}X_k-\sum_{k=1}^{n}{\mu_k}}{B_n}\leq{x}\}}\\
&=\int_{-\infty}^{x}{\frac{1}{\sqrt{2\pi}}e^{-t^2/2}\mathrm{d}t} \\
&=\Phi(x)
\end{align*}
$$
定理表明，在定理条件下，随机变量
$$
Z_n= \frac{\sum_{k=1}^{n}X_k-\sum_{k=1}^{n}{\mu_k}}{B_n}
$$
当 $n$ 很大时，近似地服从正态分布 $N(0,1)$。由此，当 $n$ 很大时，$\sum_{k=1}^{n}{X_k}=B_nZ_n+\sum_{k=1}^{n}{\mu_k}$ 近似地服从正态分布 $N(\sum_{k=1}^{n}{\mu_k}, B_n^2)$。这就是说，无论各个随机变量 $X_k(k=1,2,...)$服从什么分布，只要满足定理的条件，那么它们的和 $\sum_{k=1}^{n}{X_k}$ 当 $n$ 很大时，就近似地服从正态分布。

- 定理三：棣莫弗-拉普拉斯定理

设随机变量 $\eta_n(n=1,2,...)$ 服从参数为 $n,p(0<p<1)$ 的二项分布，则对于任意 $x$，有
$$
\lim_{n\rightarrow\infty}{P\{\frac{\eta_n-np}{\sqrt{np(1-p)}}\leq{x}\}}=\int_{-\infty}^{x}{\frac{1}{\sqrt{2\pi}}e^{-t^2/2}\mathrm{d}t}=\Phi{(x)}
$$

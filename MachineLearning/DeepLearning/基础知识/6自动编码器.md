# 自动编码器

自编码器的应用主要有两个方面

- 数据去噪
- 进行可视化而降维

自编码器可以学习到比PCA等技术更好的数据投影

## 原理

- 定义

<img src="images/自动编码器.png" alt="自动编码器" style="zoom:50%;" />

自动编码器是一种数据的压缩算法，一种使用神经网络学习数据值编码的无监督方式。

- 原理

![构建自编码器思路](images/构建自编码器思路.png)

搭建一个自动编码器需要完成下面三样工作：
```
1.搭建编码器
2.搭建解码器
3.设定一个损失函数，用以衡量由于压缩而损失掉的信息。

编码器和解码器一般都是参数化的方程，并关于损失函数可导，通常情况是使用神经网络。
```
- 类别
```
- 普通自编码器
    编解码网络使用全连接层
- 多层自编码器
- 卷积自编码器
    编解码器使用卷积结构
- 正则化自编码器
    降噪自编码器
```
## 案例

### 普通

```python
from keras.layers import Input, Dense
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 编码器的输入结构
        input_img = Input(shape=(784,))
        # 定义编码器：输出32个神经元，使用relu激活函数，（32这个值可以自己制定）
        encoder = Dense(self.encoding_dim, activation='relu')(input_img)
        # 定义解码器：输出784个神经元，使用sigmoid函数，（784这个值是输出与原图片大小一致）
        decoder = Dense(self.decoding_dim, activation="sigmoid")(encoder)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改，由于全连接层的要求，将数据转换成二维[batch, feature]
        x_train = np.reshape(x_train, (len(x_train), np.prod(x_train.shape[1:])))
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        print(x_train.shape, x_test.shape)
        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 普通自编码器
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 深度

将多个自编码器进行重叠

```python
from keras.layers import Input, Dense
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 深度自编码器
        # 编码器的输入结构
        input_img = Input(shape=(784,))
        # 定义编码器：将多个编码器进行重叠
        encoder = Dense(128, activation='relu')(input_img)
        encoder  = Dense(64, activation='relu')(encoder)
        encoder = Dense(32, activation='relu')(encoder)
        # 定义解码器：将多个解码器进行宠得
        decoder = Dense(64, activation="relu")(encoder)
        decoder = Dense(128, activation="relu")(decoder)
        decoder = Dense(784, activation='sigmoid')(decoder)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改，由于全连接层的要求，将数据转换成二维[batch, feature]
        x_train = np.reshape(x_train, (len(x_train), np.prod(x_train.shape[1:])))
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        print(x_train.shape, x_test.shape)
        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 深度自编码器
        x_test = np.reshape(x_test, (len(x_test), np.prod(x_test.shape[1:])))
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 卷积

```python
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 卷积自编码器
        """
        编码器
            Conv2D(32, (3, 3), activation='relu', padding='same')
            MaxPooling2D((2, 2), padding='same')
            Conv2D(32, (3, 3), activation='relu', padding='same')
            MaxPooling2D((2, 2), padding='same')
            输出大小为:Tensor("max_pooling2d_2/MaxPool:0", shape=(?, 7, 7, 32), dtype=float32)
        解码器:反卷积过程
            Conv2D(32, (3, 3), activation='relu', padding='same')
            UpSampling2D((2, 2))
            Conv2D(32, (3, 3), activation='relu', padding='same')
            UpSampling2D((2, 2))
            Conv2D(1, (3, 3), activation='sigmoid', padding='same')
            输出大小：Tensor("conv2d_5/Sigmoid:0", shape=(?, 28, 28, 1), dtype=float32)
        """
        # 编码器的输入结构
        input_img = Input(shape=(28, 28, 1))
        # 定义编码器
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        encoder = MaxPooling2D((2, 2), padding='same')(x)
        # 定义解码器：将多个解码器进行宠得
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoder)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        decoder = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改
        x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        print(x_train.shape, x_test.shape)
        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train, x_train, epochs=5, batch_size=256, shuffle=True, validation_data=(x_test, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 卷积自编码器
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```

### 降噪/正则

```python
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model
from keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt


class AutoEncoder():
    """
    自动编码器
    """

    def __init__(self):
        self.encoding_dim = 32
        self.decoding_dim = 784
        self.model = self.auto_encoder_model()

    def auto_encoder_model(self):
        """
        初始化自动编码器模型
        将编码器和解码器放在一起作为一个模型
        :return: auto_encoder
        """
        # 降噪自编码器
        """
        对原始数据添加噪音,随机加上正态分布的噪音
        x_train + np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
        """
        # 编码器的输入结构
        input_img = Input(shape=(28, 28, 1))
        # 定义编码器
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
        x = MaxPooling2D((2, 2), padding='same')(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        encoder = MaxPooling2D((2, 2), padding='same')(x)
        # 定义解码器：将多个解码器进行宠得
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoder)
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
        x = UpSampling2D((2, 2))(x)
        decoder = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
        # 定义完整的模型逻辑
        auto_encoder = Model(input=input_img, outputs=decoder)
        # 每个像素值的交叉熵损失（输出为sigmoid值(0, 1)，输入图片要进行归一化(0, 1)）
        auto_encoder.compile(optimizer='adam', loss="binary_crossentropy")

        return auto_encoder

    def train(self):
        """
        训练自编码器
        :return:
        """
        # 读取Mnist数据，
        (x_train, _), (x_test, _) = mnist.load_data()
        # 进行归一化处理
        x_train = x_train.astype("float32") / 255.
        x_test = x_test.astype("float32") / 255.
        # 形状修改
        x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        print(x_train.shape, x_test.shape)
        # 进行躁点数据处理
        x_train_noisy = x_train + np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
        x_test_noisy = x_test + np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)
        # 重新进行限制每个像素值的大小在0~1之间
        x_train_noisy = np.clip(x_train_noisy, 0., 1.)
        x_test_noisy = np.clip(x_test_noisy, 0., 1.)

        # 模型进行fit训练
        # 指定迭代次数
        # 指定每批次数据大小
        # 是否打乱数据
        # 验证集合
        self.model.fit(x_train_noisy, x_train, epochs=5, batch_size=256, shuffle=True,
                       validation_data=(x_test_noisy, x_test))
        return None

    def display(self):
        """
        显示前后效果对比
        :return:
        """
        (x_train, _), (x_test, _) = mnist.load_data()
        # 卷积自编码器
        x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))
        # 处理躁点数据
        x_test_noisy = x_test + np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)
        decoded_imgs = self.model.predict(x_test)
        plt.figure(figsize=(20, 4))
        # 显示5张结果
        n = 5
        for i in range(n):
            # 显示编码前
            ax = plt.subplot(2, n, i + 1)
            plt.imshow(x_test_noisy[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
            # 显示编码后
            ax = plt.subplot(2, n, i + n + 1)
            plt.imshow(decoded_imgs[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.show()


if __name__ == '__main__':
    ae = AutoEncoder()
    ae.train()
    ae.display()

```


#  深度学习进阶

## 多分类

### softmax回归

对于**多分类问题**，用 N表示种类个数，那么神经网络的输出层的神经元个数必须为$L[output]=N$, 每个神经元的输出依次对应属于N个类别当中某个具体类别的概率，即 $P(y=N_1|x),\cdots,P(y=N_n|x)$。

输出层即

$$
Z^{[L]} = W^{[L]}a^{[L-1]} + b^{[L]}
$$

Z的输出值个数为类别个数.

需要对所有的输出结果进行一下softmax公式计算

$$
a^{[L]}_i = \frac{e^{Z^{[L]}_i}}{\sum^C_{i=1}e^{Z^{[L]}_i}}
$$

并且满足
$$
\sum^C_{i=1}a^{[L]}_i = 1
$$

### 交叉熵损失

逻辑回归的损失也可以这样表示
$$
\begin{aligned}
J(\theta) 
&= -\frac{1}{m}\bigg[\sum_{i=1}^{m}{(1-y^{(i)})\log{(1-h_\theta(x^{(i)}))}+y^{(i)}\log h_\theta(x^{(i)})}\bigg] \\
&= -\frac{1}{m}\bigg[\sum_{i=1}^m\sum_{j=0}^1{1\{y^{(i)}=j\}\log{p(y^{(i)}=j|x^{(i)}; \theta})}\bigg]

\end{aligned}
$$
对于softmax回归（逻辑回归代价函数的推广，都可称之为交叉熵损失），它的代价函数公式为：
$$
L(\hat y, y) = -\sum^C_{j=1}y_j\log\hat y_j
$$
总损失函数可以记为
$$
J = \frac{1}{m}\sum^m_{i=1}L(\hat y, y)
$$
对于真实值会进行一个one-hot编码，每一个样本的所属类别都会在某个类别位置上标记。

<img src="images/交叉损失理解.png" alt="交叉损失理解" style="zoom:50%;" />

上图中，交叉熵损失为
$$
0\log(0.10)+0\log(0.05)+\cdots+0log(0.10)
$$
one_hot示例

<img src="images/onehot编码.png" alt="onehot编码" style="zoom:50%;" />

## 梯度下降改进

### 问题提出

- 梯度消失

在梯度函数上出现的以指数级递增或者递减的情况分别称为**梯度爆炸**或者**梯度消失**。

假设$g(z) = z, b^{[l]} = 0$，对于目标输出有：$\hat{y} = W^{[L]}W^{[L-1]}...W^{[2]}W^{[1]}X$

对于$W^{[l]}$的值大于 1 的情况，激活函数的值将以指数级递增；

对于$W^{[l]}$的值小于 1 的情况，激活函数的值将以指数级递减。

在计算梯度时，根据不同情况梯度函数也会以指数级递增或递减，导致训练导数难度上升，梯度下降算法的步长会变得非常小，需要训练的时间将会非常长。

- 局部最优

<img src="images/损失函数多个最小值.png" alt="损失函数多个最小值" style="zoom:50%;" />

**鞍点（saddle）**是函数上的导数为零，但不是轴上局部极值的点。通常梯度为零的点是上图所示的鞍点，而非局部最小值。减少损失的难度也来自误差曲面中的鞍点，而不是局部最低点。

<img src="images/鞍点.png" alt="鞍点" style="zoom:30%;" />

在训练较大的神经网络、存在大量参数，并且成本函数被定义在较高的维度空间时，困在极差的局部最优基本不会发生

**鞍点附近的平稳段会使得学习非常缓慢，而这也是需要后面的动量梯度下降法、RMSProp 以及 Adam 优化算法能够加速学习的原因，它们能帮助尽早走出平稳段。**

### 解决方法

#### 初始化参数策略

为什么要随机初始化权重？

如果在初始时将两个隐藏神经元的参数设置为相同的大小，那么两个隐藏神经元对输出单元的影响也是相同的，通过反向梯度下降去进行计算的时候，会得到同样的梯度大小，所以在经过多次迭代后，两个隐藏层单位仍然是对称的。无论设置多少个隐藏单元，其最终的影响都是相同的，那么多个隐藏神经元就没有了意义。

在初始化的时候，W 参数要进行随机初始化，不可以设置为 0。b 因为不存在上述问题，可以设置为 0。

以 2 个输入，2 个隐藏神经元为例：

```py
W = np.random.rand(2,2)* 0.01
b = np.zeros((2,1))
```

初始化权重的值选择？

这里将 W 的值乘以 0.01（或者其他的常数值）的原因是为了使得权重 W 初始化为较小的值，**这是因为使用 sigmoid 函数或者 tanh 函数作为激活函数时，W 比较小，则 Z=WX+b 所得的值趋近于 0，梯度较大，能够提高算法的更新速度。而如果 W 设置的太大的话，得到的梯度较小，训练过程因此会变得很慢。**

ReLU 和 Leaky ReLU 作为激活函数时不存在这种问题，因为在大于 0 的时候，梯度均为 1。

#### 批梯度下降

批梯度下降(Batch Gradient Descent)

> 批梯度下降法(btach)，即同时处理整个训练集

其在更新参数时使用所有的样本来进行更新。对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，处理速度就会比较慢。

**所以换一种方式，每次处理训练数据的一部分进行梯度下降法，则我们的算法速度会执行的更快。**

小批量梯度下降(Mini-Batch Gradient Descent)

> Mini-Batch 梯度下降法（小批量梯度下降法）每次同时处理固定大小的数据集。

使用 Mini-Batch 梯度下降法，对整个训练集的一次遍历(epoch)只做 mini-batch个样本的梯度下降，一直循环整个训练集。

随机梯度下降(stochastic gradient descent)

> mini-batch 的大小为 1，即是随机梯度下降法

- 代价函数区别

batch梯度下降法和Mini-batch 梯度下降法代价函数的变化趋势如下：

<img src="images/代价函数变换.png" alt="代价函数变换" style="zoom:50%;" />

- 优化影响

batch 梯度下降法
```
- 对所有m个训练样本执行一次梯度下降，每一次迭代时间较长，训练过程慢；
- 相对噪声低一些，成本函数总是向减小的方向下降。
```
随机梯度下降法(Mini-Batch=1)：
```
- 对每一个训练样本执行一次梯度下降，训练速度快，但丢失了向量化带来的计算加速；
- 有很多噪声，需要适当减小学习率，成本函数总体趋势向全局最小值靠近，但永远不会收敛，而是一直在最小值附近波动。
````
因此，选择一个合适的大小进行 Mini-batch 梯度下降，可以实现快速学习，也应用了向量化带来的好处，且成本函数的下降处于前两者之间。

- 大小选择

如果训练样本的大小比较小，如 $m\le2000$ 时，选择 batch 梯度下降法；

如果训练样本的大小比较大，选择 Mini-Batch 梯度下降法。为了和计算机的信息存储方式相适应，代码在 mini-batch 大小为 2 的幂次时运行要快一些。典型的大小为$2^6, 2^7,2^8,2^9$,mini-batch 的大小要符合 CPU/GPU 内存。

需要根据经验快速尝试，找到能够最有效地减少成本函数的值。

那么第二种方式是通过优化梯度下降过程，会比梯度下降算法的速度更快些

#### 动量梯度下降

- 指数加权平均

**指数加权平均（Exponentially Weight Average）**是一种常用的序列数据处理方式，通常用在序列场景如金融序列分析、温度变化序列分析。

指数加权的公式即：
$$
S_t = \begin{cases} Y_1, &t = 1 \\ \beta S_{t-1} + (1-\beta)Y_t, &t > 1 \end{cases}
$$
其中$Y_{t}$ 为 $t$下的实际值，$S_{t}$为$t$下加权平均后的值，$\beta$ 为权重值。

通过指数加权公式，对$S=Y$ 进行平滑处理，$\beta$ 越大相当于求取平均利用前面的数据比重的越多**，曲线自然就会越平滑而且越滞后。这些系数被称作**偏差修正（Bias Correction）

- 动量梯度下降

**动量梯度下降（Gradient Descent with Momentum）**是**计算梯度的指数加权平均数**，并利用该值来更新参数值。动量梯度下降法的整个过程为：
$$
S_{dW^{[l]}} = \beta S_{dW^{[l]}} + (1 - \beta) dW^{[l]}\\
S_{db^{[l]}} = \beta S_{db^{[l]}} + (1 - \beta) db^{[l]}\\
W^{[l]} := W^{[l]} - \alpha S_{dW^{[l]}}\\
b^{[l]} := b^{[l]} - \alpha S_{db^{[l]}}
$$
使用动量梯度下降时，通过累加过去的梯度值来减少抵达最小值路径上的波动，加速了收敛，因此在横轴方向下降得更快，从而得到图中红色或者紫色的曲线。**当前后梯度方向一致时，动量梯度下降能够加速学习；而前后梯度方向不一致时，动量梯度下降能够抑制震荡。**

我们可以这样形象的理解，小球在向下运动过程中会有加速度，导致越来越快，由于\beta*β*的存在使得不会一直加速运行。

#### RMSProp算法

**RMSProp（Root Mean Square Prop）**算法是在对梯度进行指数加权平均的基础上，引入平方和平方根
$$
s_{dw}=\beta s_{dw} + (1−\beta)(dw)^2 \\

s_{db} = \beta s_{db} + (1 - \beta)(db)^2\\

w := w - \alpha \frac{dw}{\sqrt{s_{dw} + \epsilon}}\\

b := b - \alpha \frac{db}{\sqrt{s_{db} + \epsilon}}
$$
其中 $\epsilon$是一个非常小的数，防止分母太小导致不稳定,当 dw 或 db 较大时，$(dw)^{2}, (db)^{2}$会较大，进而$s_{dw}$也会较大，最终使得$\frac{db}{\sqrt{s_{db} + \epsilon}}$等结果变得非常小。

最终RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 α，从而加快算法学习速度。

#### Adam算法

**Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）**将 Momentum 和 RMSProp 算法结合在一起。

假设用每一个 mini-batch 计算 dW、db，第t*t*次迭代时：
$$
v_{dW} = \beta_1 v_{dW} + (1 - \beta_1) dW\\
v_{db} = \beta_1 v_{db} + (1 - \beta_1) db\\

v^{corrected}_{dW^{[l]}} = \frac{v_{dW^{[l]}}}{1 - (\beta_1)^t}\\

s_{dW} = \beta_2 s_{dW} + (1 - \beta_2) {(dW)}^2\\
s_{db} = \beta_2 s_{db} + (1 - \beta_2) {(db)}^2\\
s^{corrected}_{dW^{[l]}} = \frac{s_{dW^{[l]}}}{1 - (\beta_1)^t}
$$
其中 $l$ 为某一层，$t$ 为移动平均第次的值

Adam 算法的参数更新：
$$
W:=W- \alpha\frac{v^{corrected}_{dW}}{\sqrt{s^{corrected}_{dW}} + \epsilon}\\
b:=b- \alpha\frac{v^{corrected}_{dW}}{\sqrt{s^{corrected}_{dW}} + \epsilon}
$$

## 正则化

## 调优与BN


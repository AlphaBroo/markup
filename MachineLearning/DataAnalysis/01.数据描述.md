[TOC]

# 统计量

## 集中趋势

集中趋势用于描述一组数据的集中位置或平均水平，代表了一组数据的典型水平，反映了一组数据中心点的位置

|        | 优点                                                   | 缺点                        |
| ------ | ------------------------------------------------------ | --------------------------- |
| 均值   | 充分利用所有数据，适用性强                             | 易受极端值影响              |
| 中位数 | 不受极端值影响                                         | 缺乏敏感性                  |
| 众数   | 当数据具有冥想是的集中趋势时，代表性好；不受极端值影响 | 缺乏唯一性，可能为0、1、2个 |



### 均值

原始数据之和除以原始数据的个数，也叫平均数
$$
\bar{x} = \frac{\sum_{i=1}^{n}x_i}{n}
$$

```python
np.mean(obj)  # 样本均值

np.average(obj)  # 样本均值
np.average(obj, weights=xxx)  # 计算加权算术平均数

obj.mean()  # 样本均值
```

- 截尾均值

计算原始数据中去掉最大N个和最小N个(或百分之N)值后的平均值。其中N可以指定为1，2，3，这是变量中心位置的一种稳健估计，但估计量本身不再服从正态分布

```python
from scipy import stats

stats.tmean(obj['xxx'])  # 计算所有数据的截尾均值
stats.tmean(obj['xxx'], (25, 30))  # 带上下界数据范围的截尾均值
```

- 缩尾均值

把原始数据中最小的N个值用第N+1小的那个数值替换，同时最大的N个值，用第N+1大的那个数值替换，然后计算均值。也是一种稳健的均值估计。

```python
from scipy import stats

stats.mstats.winsorize(obj['xxxx'], (0.05, 0.05)).mean()

stats.gmean(obj['xxx'])  # 几何平均数
stats.hmean(obj['xxx'])  # 调和平均数
```

### 中位数

中位数(median)是把所有的数据按照一定顺序进行排列，处于排序后数据最中间位置所对应的那个数值。若数据个数是奇数，中位数就是处在正中心的数值，若数据个数是偶数，中位数就是处在正中心位置左右2项数据的平均数。中位数对极端数值不敏感，也称之为位置平均数

```python
# numpy的np.median
np.median(obj['xxx'])

# pandas的pd.median
df_obj.median()

# scipy的stats.nanmedian
stats.nanmedian(obj['xxx'])
```

### 分位数

中位数把所有数据等分成2部分，与其类似的还有四分位数(quartile)、十分位数(decile)和百分位数(percentile)等，即分别用3个点、9个点和99个点将数据4等分、10等分、100等分后各分位点位置上的数值。中位数实际上就是第50个百分位数、第2个四分位数、第5个十分位数

四分位较常用，位于25%位置对应的数值叫下四分位数，记作Q1；处于75%位置对应的数值称为上四分位，记作Q3
$$
L_y = n*(\frac{y}{100})
$$
情况1：若L是一个整数，则取第L和第L+1的平均值

情况2：若L是一个小数，则取下一个最近的整数（如1.2则取2）

```python
stats.scoreatpercentile(obj['xxx'], [10, 20, 25, 50, 75, 100])  # 计算指定分位点的分位数
stats.percentileofscore(obj['xxx'], 30.27)  # 计算指定数值所处的分位点

stats.mstats.mquantiles(obj['xxx'], prob=0.5)  # 使用掩模统计函数计算中位数

stats.mstats.hdquantiles(obj['xxx'], prob=0.5)  # 计算分位数
```

### 众数

众数(mode)是指数据中出现次数最多的数值。既可以定量数据，也可应用于定性数据，是一种比较重要的集中趋势测度指标。若有若干个数据出现次数一样多，则众数有多个；当所有数据出现的次数一样多时，没有众数

```python
m = np.array([1,2,3,4,3,2,3,3,4,4,4,7,8])
stats.mode(m)  # 只给出若干众数中的第一个众数，若是没有众数，则返回值有误

# pandas
md = pd.DataFrame(m)
md.mode()
```

## 离散程度

集中趋势概括数据可以使人们大体上对数据产生初步印象，但是在统计量对数据进行高度抽象的同时，忽略了一些必要的数据信息。离散程度就提供了对数据的另一维度的信息

### 极差

极差(range)也叫全距或范围，是数据中最大值减去最小值所得的差。极差手极端值的影响，由于抛弃了几乎全部的数据信息，中间部分的数据信息无法反映，因此不能准确地描述数据的分散情况

```python
# np
np.ptp(obj['xxx'])
np.max(obj['xxx']) - np.min(obj['xxx'])

# pandas
df_obj['xxx'].max() - df_obj['xxx'].min()

# scipy
stats.mstas.mquantiles(obj['xxx'], prob=1) - stats.mstas.mquantiles(obj['xxx'], prob=0)
```

### 四分位差

四分位差(qrange)是四分位数之间的差。指第3个四分位减去第1个四分位得到的差，即上四分位与下四分位数之间的差值。反映了中间1/2数据的分散情况，其值越小，说明中间的数据越集中。四分位差不受极端值影响，在一定程度上说明了中位数对一组数据的代表程度

```python
stats.scoreatpercentile(obj['xxx'], 75) - stats.scoreatpercentile(obj['xxx'], 25)
```

### 方差和标准差

方差是每一个数的原始数值与均值的差求平方，然后求这些平方的和，再用这个平方和除以数据的个数得到的数值。即离差平方的平均数。
$$
\begin{equation}
\sigma^{2} = \frac{\sum\limits_{i=1}^{N}(x_{i}-\bar{x})^{2}}{N}
\end{equation}
$$
方差用所有数据进行计算，反映了所有数据相对于数据中心发散的平均程度。方差越大说明离散程度越高。

变形简化运算可得
$$
\sigma^{2} = \frac{1}{N}\sum_{i=1}^{N}{X_{i}^{2}}-\mu^{2}
$$


 在统计推断中，往往使用的方差是无法满足无偏性的样本修正方差，即样本在原始数据样本量基础上减1
$$
\begin{equation}
s^{2} = \frac{\sum\limits_{i=1}^{N}(x_{i}-\bar{x})^{2}}{n-1}
\end{equation}
$$
由于方差和原数据的单位不一样，比较无意义，为了保持单位的一致性，引入-标准差。

方差的算术平方根即标准差(standard deviation)，避免了因为单位平方引起的度量问题。
$$
\sigma = \sqrt{\sigma^{2}}
$$

```python
# np
np.var(obj['xxx'], ddof=1)  # 计算方差统计量，ddof表示设置计算方差时的分母为n-ddof,ddof默认为0
obj['xxx'].var(ddof=1)
np.std(obj['xxx'], ddof=1)  # 计算标准差统计量

# pandas
df_obj['xxx'].var()  # 计算方差统计量
df_obj['xxx'].std()  # 计算标准差统计量

# scipy
stats.tvar(obj['xxx'])  # 计算方差统计量
stats.nanstd(obj['xxx'])  # 计算标准差统计量
```

### 协方差

协方差(covariance)用于衡量两个变量之间的关系，其计算公式
$$
\begin{equation}
Cov(X,Y) = E(XY)-E(X)E(Y)
\end{equation}
$$

```python
# numpy
np.cov(obj['xxx1'], obj['xxx2'], bias=1, ddof=1)  # bias=1表示结果需要除以N，否则只计算分子部分；返回结果为矩阵，第i行第i列的数据表示第i组数与第j组数的协方差。对角线为方差

# pandas
obj['xxx1'].cov(obj['xxx2'])
```

### 变异系数

对于平均水平不同或计量单位不同的不同变量而言，是不能采用之前的统计量来直接比较其离散程度的。为了消除这些因素对离散程度的测度影响，就需哟啊用一个相对指标来对不同总体或样本数据的离散程度进行比较。

变异系数(coefficient of variation)是衡量相对离散程度的一个重要指标。变异系数也叫做标准差系数或离散系数，具体指一组数据的标准差与其相应的均值之比。变异系数越小，说明数据的相对离散程度也越小
$$
CV = \sigma/\bar{x}
$$

```python
# numpy
# pandas
cv = df_obj['xxx1'].var()/df_obj['xxx2'].mean()
```

## 分布形状

在对数据进行概括性分析时，对于数据的分布状况也应当有概括性的分析，才能掌握数据的全貌

数据分布的测度主要考察数据分布是否对称、偏斜程度和扁平程度如何，其主要指标有偏度和峰度等

### 偏度

偏度(skewness)是对数据分布对称性的测度。偏度的计算方法很多，常采用三阶中心矩的计算方法，其主要考察离差三次方之和与标准差的三次方的比例
$$
K = \frac{E(x-\mu)^3}{\sigma^3}   ；\mu和\sigma分别表示均值和标准差
$$
如果数据时对称的，则偏度为0；若偏度不等于0，表明数据分布时非对称的。当偏度大于0，均值右边的数据更为分散，表明数据右偏；偏度小于0，均值左边的数据更为分散，表明数据左偏。偏度的数值越大，表明数据偏斜的程度就越大。

```python
# pandas
df_obj['xxx'].skew()  # 计算偏度

# scipy
stats.skew(obj['xxx'], bias=False)   # 计算偏度
```

### 峰度

峰度(kurtosis)是用来反映数据分布曲线顶端陡峭或扁平程度的指标。所谓陡峭或扁平是针对标准正态分布而言的。峰度通常是四阶中心矩进行计算的，考察四阶矩与标准差四次方之间的比例关系
$$
K = \frac{E(x-\mu)^4}{\sigma^4}-3
$$
若数据服从标准正态分布，则峰度的值等于0（减3就是为了表示正态分布）；若峰度不等于0，则表示数据分布比正态分布更陡峭或更扁平。当峰度大于0，说明比正态分布要更陡峭；峰度小于0，说明比正态分布更平坦

```python
# pandas
df_obj['xxx'].kurt()  # 计算峰度

# scipy
stats.kurtosis(obj['xxx'], bias=False)  # 计算峰度
```

# 统计表

若进行一些复杂的描述统计分析，只考虑统计量是不够的，需要统计表。

## 统计表的基本要素

统计表的最大特点就是表格左右两端不封口，即左右两端没有竖线。但需注意，在python 默认编制的统计表格是封口的(可以指定不同格式的表格模版，也可自定义表格模版)

统计表通常分为行和列，代表行维和列维，亦即二位表格的由来。统计表中往往还有汇总的合计项，有可以分成行合计与列合计，分别统计每行或每列分析变量的汇总情况。表格与表格之间的维度叫做页维。

```python
# 为表格中的数据生成统计量
# pandas
df_obj.describe()

# scipy
stats.describe(obj[['xxx1','xxx2', 'xxx3']])
```

## 统计表的编制

pandas可以很方便地编制各种统计表格，如简单统计量表、分类汇总表(数据透视表)、交叉表等。

```python
# 读取文件建表
storesales = pd.read_csv('storesales.csv')
print(storesales.head(5))
#      id  store  method  orders  sales
# 0  1001      1       1      78  89000
# 1  1023      2       1      87  98000
# 2  1234      2       2      67  78500
# 3  1002      3       2      87  77500
# 4  1001      3       1      56  67990

# groupby建立统计表
storesales_grouped = storesales.groupby(storesales['method'])
storesales_grouped['sales', 'orders'].agg('sum')
```

pivot_table和crosstab可构建更复杂的统计表格即数据透视表

```python
pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')

# 参数
data		指定为pandas中的DataFrame
index		对应数据透视表中的行
columns		对应数据透视表中的列
values		对应数据透视表中的值
aggfunc		指定汇总的函数，默认为mean函数
margins		指定分类汇总和总计
fill_value	指定填补的缺失值
dropna		指定是否包含所有数据项都是缺失值的列

crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, dropna=True, normalize=False)
# 不需要使用data参数指定对象，而是直接在index、columns、values等中直接指定分析对象
```

示例

```python
pd.pivot_table(storesales, index=['store'], values=['orders'], aggfunc=sum)

pd.pivot_table(storesales, index=['store'], values=['orders'], aggfunc=sum, fill_value=0)

pd.pivot_table(storesales, index=['store'], columns=['method'], values=['orders', 'sales'], aggfunc=[sum, mean, len], fill_value=0)

pd.pivot_table(storesales, index=['store'], columns=['method'], values=['sales'], aggfunc=[sum], fill_value=0, margins=True)

pd.crosstab(storesales['store'], storesales['method'], values=storesales['sales'], aggfunc=[sum], margins=True) # 等价于上个pivot_table
```


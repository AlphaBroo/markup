# Tensorflow

图结构：数据(tensor)+操作(operation)

## 组件

### 图

- 图操作

查看默认图

```python
a = tf.constant(2)  # tensor
b = tf.constant(3)
c = a + b  # op
# 查看默认图
# 方法一：调用方法
default_g = tf.get_default_graph()
print('default_g:', default_g)
# 方法二：查看属性
print("a的图属性：",a.graph)
print("b的图属性：",b.graph
with tf.Session() as sess:  # 会话
    c_v = sess.run(c)
    print("c_v_res: {}". format(c_v)) 
    print("c_v的图属性：",c.graph)      
```

创建新图

```python
# 自定义图
new_g = tf.Graph()
with new_g.as_default():
    a_new = tf.constant(2)
    b_new = tf.constant(3)
    c_new = a_new + b_new
    print('c_new的图属性：', c_new.graph)
with tf.Session(graph=new_g) as new_sess:
      c_new_v = new_sess.run(c_new)
      print('c_new_v的res:{}'.format(c_new_v))
      print('new_session的图属性：', new_sess.graph)
```

- 图显示

将图序列化为本地events文件

```python
tf.summary.FileWriter('./tmp/summary', graph=sess.graph)
```

shell启动tensorboard，在浏览器中访问`127.0.0.1:6006`

```shell
tenorboard --logdir='./tmp/summary'
```

### 会话

一个运行TensorFlow operation的类，包含两种开启方式

```python
tf.Session  # 用于完整的程序当中
tf.InteractiveSession  # 用于交互式上下文中的Tensorflow，如shell
```

> `tf.Session`对象使用分布式Tensorflow运行时提供对本地计算机中的设备和远程设备的访问权限

- `__init__`

```python
__init__(target='', graph=None, config=None)

# 参数
- target: 如果将此参数留空，会话将仅使用本地计算机中的设备。可以指定grpc://网址，以便制定TensorFlow服务器的地址，这使得会话可以访问服务器控制的计算机上的所有设备
- graph:默认情况下，新的tf.Session将绑定当前的默认图
- config：此参数允许您指定一个tf.ConfigProto以便控制会话的行为。如ConfigProto协议用于打印设备使用信息
```

会话可能拥有的资源，如`tf.Variable`，`tf.QueueBase`和`tf.ReaderBase`。当这些资源不再需要时，需要释放这些资源。故常常使用`with`上下文管理器，等价于手动调用`tf.Session.close()`

```python
import tensorfow as tf

# with上下文
# 使用默认图
with tf.Session() as sess:
	res = sess.run(...)
    
# 使用新图
new_g = tf.Graph()
with tf.Session(graph=new_g) as new_sess:
    new_res = new_sess.run(...)
    
# 手动处理
sess = tf.Session()
...
sess.close()

# 运行会话并打印设备信息
sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,
                                       log_device_placement=True))
```

会话可以分配不同的资源在不同的设备上运行

```
/job:worker/replica:0/task:0/device:CPU:0
```

- `run`

```python
run(fetches, feed_dict=None, options=None, run_metadata=None)

# 参数
- fetches:单一的operation，或者列表、元组（其他不属于tensorflow的类型不行）
- feed_dict:参数允许调用者覆盖图中张量的值，运行时赋值。与tf.placeholder搭配使用，则会检查值的形状是否与占位符兼容
```

> 使用`tf.operation.eval()`也可以运行operation，但需要在会话中运行

```python
# 创建图
a = tf.constant(5)
b = tf.constant(2)
c = a + b
# 创建会话
sess = tf.Session()
# 计算C的值,两种等价
print(sess.run(c))  # print(sess.run([a,b,c]))
print(c.eval(session=sess))
```

- `feed`

`placeholder`提供占位符，`run`的时候通过`feed_dict`指定参数

```python
imoport tensorflow as tf

data1 = tf.placeholder(tf.float32)
data2 = tf.placeholder(tf.float32)
dataAdd = tf.add(data1, data2)
with tf.Session() as sess:
  print(sess.run(dataAdd, feed_dict={data1:6, data2:2}))
print('end')
```

###张量

Tensorflow的张量就是一个n维数组，类型为`tf.Tensor`。Tensor具有以下属性：type(数据类型)、shape(形状)

- 张量的类型

| 数据类型     | python类型   | 描述                                               |
| ------------ | ------------ | -------------------------------------------------- |
| DT_FLOAT     | tf.float32   | 32位浮点数                                         |
| DT_DOUBLE    | tf.float64   | 64位浮点数                                         |
| DT_INT64     | tf.int64     | 64位有符号整型                                     |
| DT_INT32     | tf.int32     | 32位有符号整型                                     |
| DT_INT16     | tf.int16     | 16位有符号整型                                     |
| DT_INT8      | tf.int8      | 8位有符号整型                                      |
| DT_UINT8     | tf.uint8     | 8位无符号整型                                      |
| DT_STRING    | tf.string    | 可变长度的字节数组，每一个张量元素都是一个字节数组 |
| DT_BOOL      | tf.bool      | 布尔型                                             |
| DT_COMPLEX64 | tf.complex64 | 由两个32位浮点数组成的复数：实数和虚数             |
| DT_QINT32    | tf.qint32    | 用于量化Ops的32位有符号整型                        |
| DT_QINT8     | tf.qint8     | 用于量化Ops的8位有符号整型                         |
| DT_QUINT8    | tf.quint8    | 用于量化Ops的8位无符号整型                         |

- 张量的阶

| 阶   | 数学实例 | python     | 例子                                                |
| ---- | -------- | ---------- | --------------------------------------------------- |
| 0    | 纯量     | 只有大小   | s=23                                                |
| 1    | 向量     | 大小和方向 | v =[1,2,3]                                          |
| 2    | 矩阵     | 数据表     | m=[[1,2,3],[4,5,6],[7,8,9]]                         |
| 3    | 3阶张量  | 数据立体   | t= [[[2],[4],[6]],[[8],[10],[12]],[[14],[16],[18]]] |
| n    | n阶      | ...        | ...                                                 |

示例

```python
tensor1 = tf.constant(4.0)
tensor2 = tf.constant([1,2,3,4])
linear_squares = tf.constant([[4],[9],[16],[25]], dtype=tf.int32)

print(tensor1)  # Tensor("Const:0", shape=(), dtype=float32)
print(tensor2)  # Tensor("Const_1:0", shape=(4,), dtype=int32)
print(linear_squares)  # Tensor("Const_2:0", shape=(4, 1), dtype=int32)
```
- 创建张量

```python
# 固定值
tf.zeros(shape, dtype=tf.float32, name=None)  # 创建所有元素为零的张量
tf.zeros_like(tensor, dtype=tf.float32, name=None)  # 创建与指定tensor相同类型和形状的所有元素为零的张量
tf.ones(shape, dtype=tf.float32, name=None)  # 创建所有元素为1的张量
tf.ones_like(tensor, dtype=None, name=None)  # 创建与指定tensor相同类型和形状的所有元素为1的张量
tf.fill(dims, value, name=None)  # 创建一个相撞为dims，并填充了标量值的张量
tf.constant(value, dtype=None, shape=None, name='Const')  # 创建一个常数张量

# 随机张量
tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)  # 从截断的正态分布中输出随机值，和tf.random()一样，但是所有数字都不会超过两个标准差
tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)  # 从正态分布中输出随机值，由随机正态分布的数字组成的矩阵

# 特殊方法
tf.Variable
tf.placeholder
```

- 张量的变换

类型的改变

```python
tf.string_to_number(string_tensor, out_type=None, name=None)
tf.to_double(x, name='ToDouble')
tf.to_float(x, name='ToFloat')
tf.to_bfloat(x, name='ToBFloat16')
tf.to_int32(x, name='ToInt32')
tf.to_int64(x, name='ToInt64')
tf.cast(x, dtype, name=None)
```

形状的改变

```python
# 有两种形状变换，动态形状和静态形状

```



### 操作

一个操作对象（Operation）是TensorFlow图中的一个节点，可以接收0个或多个输入Tensor，并且可以输出0个或者多个Tensor，Operation对象是通过op构造函数(`tf.matmul()`)创建的。

```python
import tensorflow as tf
data1 = tf.constant(6)  # tf.constant是操作函数，输入int值，经过Const操作对象，输出tensor对象data1
data2 = tf.constant(2) 
dataAdd = tf.add(data1, data2)  # tf.add是操作函数，输入是tensor对象data1/data2，经过Add操作对象，输出tensor对象dataAdd
```

- 指令名称

一个图是一个命名空间，一个命名空间中指令名称不能重复；对于新的图，张量相当于重新开始，可以与其他图的指令名称相同

```python
import tensorflow as tf
data1 = tf.constant(6)
print(data1)  # Tensor("Const:0", shape=(), dtype=int32)
```

经过操作对象产生的Tensor名称的形式为`<OP_NAME>:<i>`，其中，`<OP_NAME>`是生成该张量的指令的名称；`<i>`是一个整数，表示该张量在指令的输出中的索引。

```python
# 修改指令名称
a = tf.constant(3, name='a')  # Tensor("a:0", shape=(), dtype=int32)
```

- 常见OP构造函数

| 类型           | 实例                                           |
| -------------- | ---------------------------------------------- |
| 标量运算       | add,sub,mul,div,exp,log,greater,lesse,equal    |
| 向量运算       | concat,slice,splot,constant,rank,shape,shuffle |
| 矩阵运算       | matmul,matrixinverse,matrixdateminant          |
| 带状态的运算   | variable,assgin,assginadd                      |
| 神经网络组建   | softmax,sigmod,relu,convolution,max_pool       |
| 存储，恢复     | save,restore                                   |
| 队列及同步运算 | Enqueue,Dequeue,MutexAcquire,MutexRelease      |
| 控制流         | Merge,Switch,Enter,Leave,NextIteration         |

- 示例

常量间

```python
import tensorflow as tf
data1 = tf.constant(6)
data2 = tf.constant(2)
dataAdd = tf.add(data1, data2)  # 加
dataMul = tf.multiply(data1, data2)  # 乘
dataSub = tf.subtract(data1, data2)  # 减
dataDiv = tf.divide(data1, data2) # 除
with tf.Session() as sess:
  print(
    sess.run(dataAdd),
    sess.run(dataMul),
    sess.run(dataSub),
    sess.run(dataDiv)
       )
```

常量与变量

```python
import tensorflow as tf
data1 = tf.constant(6)
data2 = tf.Variable(2)
dataAdd = tf.add(data1, data2)
dataCopy = tf.assign(data2, dataAdd)  # data2 <= dataAdd
dataMul = tf.Multiply(data1, data2)
dataSub = tf.subtract(data1, data2)
dataSiv = tf.divide(data1, data2)
init = tf.global_variables_initializer()
with tf.Session() as sess:
  sess.run(init)
  print(
  	sess.run(dataAdd),
    sess.run(dataMul),
    sess.run(dataSub),
    sess.run(dataDiv)
  )
  print('sess.run(dataCopy)', sess.run(dataCopy))  # 8
  print('dataCopy.eval()', dataCopy.eval())  # 14
  print('tf.get_default_session()', tf.get_default_session().run(dataCopy))  # 20
```


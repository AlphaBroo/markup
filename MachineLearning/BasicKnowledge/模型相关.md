# 模型相关

## 评价

### KNN

准确度
$$
accuracy = \frac{\sum_{i=1}^m{(y_{test}^{(i)}==\hat{y}_{test}^{(i)})}}{m}
$$

### 线性回归

均方误差(Mean Squared Error)
$$
MSE = \frac{\sum_{i=1}^m{(y_{test}^{(i)}-\hat{y}_{test}^{(i)})^2}}{m}
$$


根均方误差(Root Mean Squared Error)

```
可降低量纲的影响
```

$$
RMSE = \sqrt{MSE}
$$

平均绝对误差(Mean Absolute Error)
$$
MAE = \frac{\arrowvert y_{test}^{(i)}-\hat{y}_{test}^{(i)}\arrowvert}{m}
$$
R方

```
可使用于不同量纲(业务)情况下比较,小于等于1，
越大表示模型越好，
等于基准模型时为0，
小于0时表示训练的模型还不如基准模型，可能不存在任何线性关系
```

$$
R^2 = 1 - \frac{SS_{redidual}}{SS_{total}}=1 - \frac{\sum_i{(\hat{y}^{(i)}-y^{(i)})^2}}{\sum_i{(\bar{y}^{(i)}-y^{(i)})^2}} =1 - \frac{(\sum_{i=1}^m{(\hat{y}^{(i)}-y^{(i)})^2})/m}{(\sum_{i=1}^m{(\bar{y}^{(i)}-y^{(i)})^2})/m}= 1 - \frac{MSE(\hat{y}, y)}{Var(y)}
$$



示例

```python
# metrics.py
import numpy as np
from math import sqrt


def accuracy_score(y_true, y_predict):
    """计算y_true和y_predict之间的准确率"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum(y_true == y_predict) / len(y_true)


def mean_squared_error(y_true, y_predict):
    """计算y_true和y_predict之间的MSE"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum((y_true - y_predict)**2) / len(y_true)


def root_mean_squared_error(y_true, y_predict):
    """计算y_true和y_predict之间的RMSE"""

    return sqrt(mean_squared_error(y_true, y_predict))


def mean_absolute_error(y_true, y_predict):
    """计算y_true和y_predict之间的RMSE"""
    assert len(y_true) == len(y_predict), \
        "the size of y_true must be equal to the size of y_predict"

    return np.sum(np.absolute(y_true - y_predict)) / len(y_true)


def r2_score(y_true, y_predict):
    """计算y_true和y_predict之间的R Square"""

    return 1 - mean_squared_error(y_true, y_predict)/np.var(y_true)

```

## 超参数

模型参数：算法过程中学习的参数

超参数：在算法运行前需要决定的参数

超参数选择

```
1. 领域知识
2. 经验数值
3. 实验搜索
```

实验搜索

```python
best_method = ""
best_score = 0.0
best_k = -1
for method in ["uniform", "distance"]:
		for k in range(1, 11):
  			knn_clf = KNeighborsClassifier(n_neighbors=k)
    		knn_clf.fit(X_train, y_train)
    		score = knn_clf.score(X_test, y_test)
    		if score > best_score:
      			best_k = k
      			best_score = score
            best_method = method
print("best_k = ", best_k)
print("best_score = ", best_score)
print("best_method = ", best_method)
```





